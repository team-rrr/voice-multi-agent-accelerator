<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice Multi-Agent Assistant - Appointment Preparation</title>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <style>
    body {
      margin: 0;
      padding: 20px;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      color: #333;
    }

    .container {
      max-width: 800px;
      margin: 0 auto;
      background: white;
      border-radius: 12px;
      padding: 30px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.2);
    }

    h1 {
      text-align: center;
      color: #4a5568;
      margin-bottom: 10px;
      font-size: 2.2rem;
    }

    .subtitle {
      text-align: center;
      color: #718096;
      margin-bottom: 30px;
      font-size: 1.1rem;
    }

    .mode-selector {
      display: flex;
      justify-content: center;
      margin-bottom: 30px;
      gap: 10px;
    }

    .mode-btn {
      padding: 10px 20px;
      border: 2px solid #4299e1;
      background: white;
      color: #4299e1;
      border-radius: 25px;
      cursor: pointer;
      transition: all 0.3s ease;
      font-weight: 500;
    }

    .mode-btn.active {
      background: #4299e1;
      color: white;
    }

    .mode-btn:hover {
      transform: translateY(-2px);
    }

    .voice-only {
      display: none;
    }

    .voice-only.active {
      display: inline-block;
    }

    .mode-controls {
      display: flex;
      gap: 12px;
      justify-content: center;
      align-items: center;
      margin-bottom: 15px;
      flex-wrap: nowrap;
      padding: 15px 20px;
      background: #f8fafc;
      border-radius: 12px;
      border: 2px solid #e2e8f0;
    }

    .controls {
      display: flex;
      gap: 12px;
      justify-content: center;
      align-items: center;
      margin-bottom: 20px;
      flex-wrap: nowrap;
    }

    button {
      padding: 10px 20px;
      font-size: 0.9rem;
      border: none;
      border-radius: 6px;
      cursor: pointer;
      transition: all 0.3s ease;
      font-weight: 500;
      min-width: 140px;
      text-align: center;
      white-space: nowrap;
    }

    #connectBtn {
      background: linear-gradient(135deg, #4299e1, #3182ce);
      color: white;
    }

    #connectBtn:hover {
      transform: translateY(-2px);
      box-shadow: 0 5px 15px rgba(66, 153, 225, 0.4);
    }

    #disconnectBtn {
      background: linear-gradient(135deg, #e53e3e, #c53030);
      color: white;
    }

    #disconnectBtn:disabled {
      background: #cbd5e0;
      cursor: not-allowed;
      transform: none;
    }

    .voice-controls {
      display: none;
      justify-content: center;
      gap: 12px;
      margin-bottom: 20px;
      align-items: center;
    }

    .voice-controls.active {
      display: flex;
    }

    #startVoiceBtn {
      background: linear-gradient(135deg, #48bb78, #38a169);
      color: white;
    }

    #stopVoiceBtn {
      background: linear-gradient(135deg, #ed8936, #dd6b20);
      color: white;
    }

    .text-input-area {
      display: none;
      margin-bottom: 20px;
    }

    .text-input-area.active {
      display: flex;
      gap: 10px;
    }

    #messageInput {
      flex: 1;
      padding: 12px;
      border: 2px solid #e2e8f0;
      border-radius: 8px;
      font-size: 1rem;
    }

    #messageInput:focus {
      outline: none;
      border-color: #4299e1;
      box-shadow: 0 0 0 3px rgba(66, 153, 225, 0.1);
    }

    #sendBtn {
      background: linear-gradient(135deg, #805ad5, #6b46c1);
      color: white;
      padding: 12px 20px;
    }

    .status {
      text-align: center;
      padding: 10px;
      border-radius: 8px;
      margin-bottom: 20px;
      font-weight: 500;
    }

    .status.connected {
      background: #c6f6d5;
      color: #22543d;
      border: 1px solid #9ae6b4;
    }

    .status.disconnected {
      background: #fed7d7;
      color: #742a2a;
      border: 1px solid #feb2b2;
    }

    .card-display {
      background: #f8f9ff;
      border: 2px solid #e2e8f0;
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      display: none;
      transition: opacity 0.3s ease, transform 0.3s ease;
    }

    .card-display.active {
      display: block;
    }

    .card-title {
      font-size: 1.3rem;
      font-weight: bold;
      color: #2d3748;
      margin-bottom: 15px;
      text-align: center;
    }

    .card-section {
      margin-bottom: 15px;
      padding: 12px;
      background: white;
      border-radius: 6px;
      border-left: 4px solid #4299e1;
    }

    .card-section h3 {
      margin: 0 0 8px 0;
      color: #2d3748;
      font-size: 1rem;
    }

    .card-section ul {
      margin: 0;
      padding-left: 20px;
    }

    .card-section li {
      margin: 4px 0;
      color: #4a5568;
    }

    .logs {
      background: #f7fafc;
      border: 2px solid #e2e8f0;
      border-radius: 8px;
      padding: 20px;
      max-height: 400px;
      overflow-y: auto;
      font-family: 'Consolas', 'Monaco', monospace;
      font-size: 0.9rem;
      scroll-behavior: smooth;
    }

    .log-entry {
      margin: 8px 0;
      padding: 8px 12px;
      border-radius: 6px;
      border-left: 4px solid;
      line-height: 1.5;
      animation: fadeInUp 0.2s ease-out;
    }

    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(5px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .log-entry p {
      margin: 6px 0;
      line-height: 1.5;
    }

    .log-entry p:first-child {
      margin-top: 0;
    }

    .log-entry p:last-child {
      margin-bottom: 0;
    }

    .log-entry p:empty {
      display: none; /* Hide empty paragraphs */
    }

    .log-entry ul {
      margin: 8px 0;
      padding-left: 20px;
      list-style-type: disc;
    }

    .log-entry li {
      margin: 3px 0;
      line-height: 1.4;
    }

    .log-entry strong {
      font-weight: 600;
      color: #2d3748;
    }

    .log-entry br {
      margin: 0;
      line-height: 0;
    }

    /* Remove extra spacing from empty elements */
    .log-entry *:empty {
      display: none;
    }

    .log-sent {
      background: #ebf8ff;
      border-left-color: #3182ce;
      color: #2a4a6b;
    }

    .log-received {
      background: #f0fff4;
      border-left-color: #38a169;
      color: #22543d;
    }

    .log-voice {
      background: #faf5ff;
      border-left-color: #805ad5;
      color: #553c9a;
    }

    .log-error {
      background: #fed7d7;
      border-left-color: #e53e3e;
      color: #742a2a;
    }

    .audio-indicator {
      display: none;
      text-align: center;
      margin: 10px 0;
      color: #805ad5;
      font-weight: 500;
    }

    .audio-indicator.active {
      display: block;
      animation: pulse 1.5s ease-in-out infinite;
    }

    .thinking-indicator {
      display: none;
      text-align: center;
      margin: 15px 0;
      padding: 12px;
      background: #f7fafc;
      border: 2px solid #4299e1;
      border-radius: 8px;
      color: #2d3748;
      font-weight: 500;
      position: relative;
    }

    .thinking-indicator.active {
      display: block;
    }

    .thinking-indicator::before {
      content: "";
      display: inline-block;
      width: 8px;
      height: 8px;
      background: #4299e1;
      border-radius: 50%;
      margin-right: 8px;
      animation: thinkingPulse 1.4s ease-in-out infinite;
    }

    .streaming-transcript {
      background: #f0fff4;
      border: 2px solid #68d391;
      border-radius: 8px;
      padding: 12px;
      margin: 10px 0;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      color: #22543d;
      font-size: 0.95rem;
      display: none;
      position: relative;
      animation: streamingPulse 1.5s ease-in-out infinite;
    }

    .streaming-transcript.active {
      display: block;
    }

    .streaming-transcript::before {
      content: "üé§ AI Speaking: ";
      font-weight: 600;
      color: #2f855a;
    }

    .streaming-transcript.partial::after {
      content: " ‚ñã";
      color: #68d391;
      animation: blink 1s infinite;
    }

    .thinking-dots {
      display: inline-block;
      margin-left: 5px;
    }

    .thinking-dots::after {
      content: "";
      animation: thinkingDots 1.4s steps(4, end) infinite;
    }

    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.5; }
    }

    @keyframes thinkingPulse {
      0%, 100% { 
        opacity: 0.4;
        transform: scale(1);
      }
      50% { 
        opacity: 1;
        transform: scale(1.2);
      }
    }

    @keyframes thinkingDots {
      0% { content: ""; }
      25% { content: "."; }
      50% { content: ".."; }
      75% { content: "..."; }
      100% { content: ""; }
    }

    @keyframes streamingPulse {
      0%, 100% { 
        border-color: #68d391;
        background: #f0fff4;
      }
      50% { 
        border-color: #48bb78;
        background: #c6f6d5;
      }
    }

    @keyframes blink {
      0%, 50% { opacity: 1; }
      51%, 100% { opacity: 0; }
    }


  </style>
</head>
<body>
  <div class="container">
    <h1>Voice Multi-Agent Assistant</h1>
    <div class="subtitle">AI-powered appointment preparation with personalized guidance</div>

    <!-- Mode Selection Row -->
    <div class="mode-controls">
      <button class="mode-btn active" onclick="setMode('voice')" id="voiceModeBtn">
        Voice Mode
      </button>
      <button class="mode-btn" onclick="setMode('text')" id="textModeBtn">
        Text Mode
      </button>
    </div>

    <!-- Action Controls Row -->
    <div class="controls">
      <button id="connectBtn" onclick="connectWebSocket()">
        Connect
      </button>
      <button id="disconnectBtn" onclick="disconnectWebSocket()" disabled>
        Disconnect
      </button>
      <button id="startVoiceBtn" onclick="startVoice()" disabled class="voice-only">
        Start Speaking
      </button>
      <button id="stopVoiceBtn" onclick="stopVoice()" disabled class="voice-only">
        Stop Speaking
      </button>
    </div>

    <div class="text-input-area" id="textInputArea">
      <input type="text" id="messageInput" placeholder="Type your message here..." />
      <button id="sendBtn" onclick="sendTextMessage()">Send</button>
    </div>

    <div class="audio-indicator" id="audioIndicator">
      üîä Processing voice...
    </div>

    <div class="thinking-indicator" id="thinkingIndicator">
      ü§î AI is thinking<span class="thinking-dots"></span>
    </div>

    <div class="streaming-transcript" id="streamingTranscript">
    </div>

    <div class="status disconnected" id="status">
      Disconnected - Click "Connect to AI Assistant" to start
    </div>

    <!-- Logs Section -->
    <div id="logs" class="logs">
      <div class="log-entry">
        <strong>Welcome!</strong> This is the Voice Multi-Agent Assistant.
        <br>‚Ä¢ Voice Mode: Speak about your medical appointments and get personalized preparation guidance
        <br>‚Ä¢ Text Mode: Type your appointment details for structured responses
        <br><br><strong>Try saying:</strong> "I have an appointment with Dr. Smith next week for chest pain"
      </div>
    </div>

    <!-- Card Display (Modal Style) -->
    <div id="cardDisplay" class="card-display">
      <div class="card-header">
        <h3 id="cardTitle" class="card-title">Appointment Preparation Guide</h3>
        <button class="card-close" onclick="document.getElementById('cardDisplay').classList.remove('active')">&times;</button>
      </div>
      <div id="cardContent" class="card-content"></div>
    </div>
  </div>

  <script>
    let socket;
    let currentMode = 'voice';
    let mediaStream;
    let audioContext;
    let source;
    let processor;
    let isRecording = false;
    let workletNode;
    let readyMessageShown = false;
    let isProcessingResponse = false;
    let responseBuffer = null;
    let lastTranscriptTime = 0;
    let thinkingTimeout = null;
    let streamingTranscriptElement = null;

    // Professional logging utility
    const ConversationLogger = {
      logPrefix: '[Conversation]',
      
      userInput: function(text, type = 'voice') {
        console.log(`${this.logPrefix} User input received:`, {
          type: type,
          content: text.substring(0, 100) + (text.length > 100 ? '...' : ''),
          length: text.length,
          timestamp: new Date().toISOString()
        });
      },
      
      agentResponse: function(response, hasCard = false) {
        console.log(`${this.logPrefix} Agent response:`, {
          spoken_length: response.length,
          has_card: hasCard,
          timestamp: new Date().toISOString()
        });
      },
      
      cardDisplayed: function(cardData) {
        console.log(`${this.logPrefix} Card displayed:`, {
          title: cardData.title,
          preparation_items: cardData.preparation_items?.length || 0,
          questions: cardData.questions_to_ask?.length || 0,
          timestamp: new Date().toISOString()
        });
      },
      
      flowState: function(state, details = {}) {
        console.log(`${this.logPrefix} Flow state:`, {
          state: state,
          ...details,
          timestamp: new Date().toISOString()
        });
      },

      error: function(component, error) {
        console.error(`${this.logPrefix} Error in ${component}:`, error);
      }
    };

    function setMode(mode) {
      currentMode = mode;
      
      // Update mode buttons
      document.getElementById('voiceModeBtn').classList.toggle('active', mode === 'voice');
      document.getElementById('textModeBtn').classList.toggle('active', mode === 'text');
      
      // Show/hide voice-specific buttons
      document.getElementById('startVoiceBtn').classList.toggle('active', mode === 'voice');
      document.getElementById('stopVoiceBtn').classList.toggle('active', mode === 'voice');
      
      // Show/hide text input area
      document.getElementById('textInputArea').classList.toggle('active', mode === 'text');
      
      addLog(`Switched to ${mode.toUpperCase()} mode`, 'info');
    }

    function addLog(message, type = 'info') {
      const logs = document.getElementById('logs');
      const entry = document.createElement('div');
      entry.className = `log-entry log-${type}`;
      
      // Extract the actual content after emoji/prefix for AI responses
      let displayMessage = message;
      let actualContent = message;
      
      // For AI responses, separate the prefix from the content and log professionally
      if (message.includes('ü§ñ AI Response: ')) {
        const parts = message.split('ü§ñ AI Response: ');
        if (parts.length > 1) {
          displayMessage = 'AI Response: ';
          actualContent = parts[1];
          ConversationLogger.agentResponse(actualContent);
        }
      }
      
      // Format only the actual content, not the emoji/prefix
      const formattedContent = actualContent === message ? 
        formatConversationText(message) : 
        displayMessage + formatConversationText(actualContent);
      
      entry.innerHTML = `<strong>${new Date().toLocaleTimeString()}</strong>: ${formattedContent}`;
      
      // Use requestAnimationFrame to batch DOM updates and reduce flickering
      requestAnimationFrame(() => {
        logs.appendChild(entry);
        
        // Limit log entries to prevent performance issues
        const entries = logs.querySelectorAll('.log-entry');
        if (entries.length > 50) {
          entries[0].remove();
        }
        
        // Smooth scroll to bottom without jarring jumps
        logs.scrollTo({
          top: logs.scrollHeight,
          behavior: 'smooth'
        });
      });
    }

    function formatConversationText(text) {
      if (!text || typeof text !== 'string') return text;
      
      // First, check if marked library is available
      if (typeof marked !== 'undefined') {
        try {
          // Configure marked for safe HTML rendering
          marked.setOptions({
            breaks: true, // Convert line breaks to <br>
            sanitize: false, // We trust our AI responses
            smartypants: true, // Smart quotes and dashes
            gfm: true, // GitHub Flavored Markdown
          });
          
          // Clean up the text first
          let cleaned = text
            .replace(/\r\n/g, '\n')  // Normalize line endings
            .replace(/\n\s*\n\s*\n/g, '\n\n')  // Remove triple+ newlines
            .trim();
          
          // Convert common bullet formats to Markdown lists
          cleaned = cleaned
            .replace(/\n‚Ä¢ /g, '\n* ')  // Convert ‚Ä¢ to *
            .replace(/\n- /g, '\n* ')  // Convert - to *
            .replace(/^\* /gm, '* ')   // Ensure lists start properly
            .replace(/^([^*\n])/gm, '\n$1'); // Add spacing before non-list items
          
          // Parse with marked
          const html = marked.parse(cleaned);
          
          // Clean up the generated HTML
          return html
            .replace(/^\s*<p>\s*<\/p>\s*/g, '') // Remove empty paragraphs at start
            .replace(/\s*<p>\s*<\/p>\s*$/g, '') // Remove empty paragraphs at end
            .replace(/<p>\s*<\/p>/g, '')        // Remove empty paragraphs anywhere
            .trim();
            
        } catch (e) {
          console.warn('[Markdown] Parsing failed, using fallback formatting:', e);
          // Fall through to basic formatting
        }
      }
      
      // Fallback: Basic formatting (original implementation)
      let cleaned = text
        .replace(/\r\n/g, '\n')
        .replace(/\n\s*\n\s*\n/g, '\n\n')
        .trim();
      
      // Handle bold text formatting (**text** to <strong>text</strong>)
      cleaned = cleaned.replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>');
      
      // Split into sections for better processing
      let sections = cleaned.split(/\n\s*\n/);
      let formattedSections = [];
      
      for (let section of sections) {
        if (!section.trim()) continue;
        
        // Check if this section contains bullet points
        if (section.includes('\n‚Ä¢ ') || section.includes('\n* ') || section.includes('\n- ')) {
          let lines = section.split('\n');
          let beforeList = [];
          let listItems = [];
          let inList = false;
          
          for (let line of lines) {
            line = line.trim();
            if (!line) continue;
            
            if (line.startsWith('‚Ä¢ ') || line.startsWith('* ') || line.startsWith('- ')) {
              inList = true;
              let itemText = line.replace(/^[‚Ä¢\*\-]\s*/, '');
              listItems.push(`<li>${itemText}</li>`);
            } else if (!inList) {
              beforeList.push(line);
            } else {
              if (line.startsWith('‚Ä¢ ') || line.startsWith('* ') || line.startsWith('- ')) {
                let itemText = line.replace(/^[‚Ä¢\*\-]\s*/, '');
                listItems.push(`<li>${itemText}</li>`);
              } else {
                if (listItems.length > 0) {
                  formattedSections.push(
                    (beforeList.length > 0 ? `<p>${beforeList.join(' ')}</p>` : '') +
                    `<ul>${listItems.join('')}</ul>`
                  );
                  beforeList = [line];
                  listItems = [];
                  inList = false;
                }
              }
            }
          }
          
          let result = '';
          if (beforeList.length > 0) {
            result += `<p>${beforeList.join(' ')}</p>`;
          }
          if (listItems.length > 0) {
            result += `<ul>${listItems.join('')}</ul>`;
          }
          
          if (result) formattedSections.push(result);
          
        } else {
          formattedSections.push(`<p>${section.trim()}</p>`);
        }
      }
      
      return formattedSections.join('');
    }

    function updateStatus(text, connected) {
      const status = document.getElementById('status');
      status.textContent = text;
      status.className = `status ${connected ? 'connected' : 'disconnected'}`;
    }

    function connectWebSocket() {
      const wsProtocol = window.location.protocol === "https:" ? "wss" : "ws";
      const wsHost = window.location.host;
      const endpoint = currentMode === 'voice' ? '/ws/voice' : '/ws/text';
      
      socket = new WebSocket(`${wsProtocol}://${wsHost}${endpoint}`);
      socket.binaryType = "arraybuffer";

      socket.onopen = () => {
        addLog(`Connected to ${currentMode.toUpperCase()} endpoint`, "received");
        updateStatus(`Connected in ${currentMode.toUpperCase()} mode`, true);
        document.getElementById("connectBtn").disabled = true;
        document.getElementById("disconnectBtn").disabled = false;
        
        if (currentMode === 'voice') {
          document.getElementById("startVoiceBtn").disabled = false;
          initAudioContext();
        }
      };

      socket.onmessage = async (event) => {
        if (event.data instanceof ArrayBuffer) {
          // Handle binary audio data (prioritize this like call-center project)
          try {
            hideThinkingIndicator(); // Hide thinking indicator when AI starts speaking
            await playAudio(event.data);
            showAudioIndicator();
          } catch (e) {
            console.error("[Audio] Playback failed:", e);
            addLog(`Audio playback error: ${e.message}`, "error");
          }
        } else if (typeof event.data === "string") {
          try {
            const data = JSON.parse(event.data);
            
            // Handle JSON messages for transcription, stop audio, etc.
            if (data.Kind === "StopAudio") {
              addLog("üõë Audio stopped", "voice");
              // Stop any ongoing audio playback
              if (workletNode) {
                workletNode.port.postMessage({ clear: true });
              }
            } else if (data.Kind === "Transcription") {
              addLog(`üìù ${data.Text}`, "received");
            } else if (data.Kind === "AudioData" && data.AudioData && data.AudioData.Data) {
              // Fallback: Decode base64 audio data (should not happen with raw_audio=True)
              const base64Audio = data.AudioData.Data;
              const audioBytes = base64ToArrayBuffer(base64Audio);
              await playAudio(audioBytes);
              showAudioIndicator();
            } else {
              // Handle regular text messages
              handleTextMessage(data);
            }
          } catch (e) {
            addLog(`Raw message: ${event.data}`, "received");
          }
        } else {
          console.log("[WebSocket] Unknown message type received:", {
            type: typeof event.data,
            data: event.data,
            timestamp: new Date().toISOString()
          });
        }
      };

      socket.onclose = () => {
        addLog("Disconnected from AI Assistant", "info");
        updateStatus("Disconnected", false);
        document.getElementById("connectBtn").disabled = false;
        document.getElementById("disconnectBtn").disabled = true;
        document.getElementById("startVoiceBtn").disabled = true;
        document.getElementById("stopVoiceBtn").disabled = true;
        readyMessageShown = false; // Reset flag for next connection
        
        // Clean up indicators
        hideThinkingIndicator();
        hideStreamingTranscript();
      };

      socket.onerror = (err) => {
        addLog("WebSocket connection error", "error");
        console.error("[WebSocket] Connection error:", err);
      };
    }

    function disconnectWebSocket() {
      if (isRecording) {
        stopVoice();
      }
      if (socket) {
        socket.close();
      }
    }

    function handleTextMessage(data) {
      const type = data.type || 'unknown';
      console.log('[WebSocket] Message received:', { 
        type: type, 
        session: data.session_id || 'unknown',
        keys: Object.keys(data),
        timestamp: new Date().toISOString()
      });
      
      switch (type) {
        case 'ready':
          if (!readyMessageShown) {
            addLog(`‚úÖ ${data.text}`, "received");
            readyMessageShown = true;
          }
          break;
        case 'orchestration_response':
          // Handle multi-agent response - buffer it to prevent flickering
          hideThinkingIndicator(); // Hide thinking indicator when response starts
          isProcessingResponse = true;
          responseBuffer = data;
          
          // Delay processing slightly to avoid flickering with real-time transcripts
          setTimeout(() => {
            if (responseBuffer && responseBuffer.spoken_response) {
              const cleanResponse = responseBuffer.spoken_response.trim();
              if (cleanResponse) {
                addLog(`ü§ñ AI Response: ${cleanResponse}`, "voice");
              }
            }
            if (responseBuffer && responseBuffer.card_data) {
              displayCard(responseBuffer.card_data);
              addLog(`üìã Generated appointment preparation checklist`, "received");
            }
            isProcessingResponse = false;
            responseBuffer = null;
          }, 100); // Small delay to batch updates and reduce flickering
          break;
        case 'card':
          // Handle card data from voice orchestration
          if (data.payload && !isProcessingResponse) {
            displayCard(data.payload);
            // Log card display professionally
            if (!document.getElementById('cardDisplay').classList.contains('active')) {
              ConversationLogger.cardDisplayed(data.payload);
              addLog(`Generated appointment preparation checklist`, "received");
            }
          }
          break;
        case 'ai_response':
          // Log AI responses immediately in conversation log
          if (data.text && data.text.trim()) {
            addLog(`ü§ñ AI Response: ${data.text.trim()}`, "voice");
          }
          break;
        case 'echo':
          addLog(`Echo: ${data.text.replace('Echo: ', '')}`, "received");
          break;
        case 'Transcription':
          // Handle streaming transcription for real-time feedback
          hideThinkingIndicator(); // Hide thinking when transcription starts
          
          if (data.text && data.text.trim()) {
            // Check if this is a partial or final transcript
            const isPartial = data.partial !== false; // Default to partial unless explicitly final
            const transcriptText = data.text.trim();
            
            // Update or create streaming transcript display
            updateStreamingTranscript(transcriptText, isPartial);
            
            // Only log final transcripts to avoid spam
            if (!isPartial) {
              addLog(`ü§ñ AI Response: ${transcriptText}`, "voice");
            }
          }
          break;
        case 'error':
          addLog(`‚ùå Error: ${data.text}`, "error");
          break;
        default:
          // Reduce frequency of unknown message logging to prevent spam
          if (!isProcessingResponse) {
            const text = data.text || JSON.stringify(data);
            addLog(`üì® ${type}: ${text}`, "received");
          }
      }
    }

    function displayCard(cardData) {
      const cardDisplay = document.getElementById('cardDisplay');
      const cardTitle = document.getElementById('cardTitle');
      const cardContent = document.getElementById('cardContent');

      // Prevent duplicate card displays
      if (cardDisplay.classList.contains('active') && cardDisplay.dataset.cardId === JSON.stringify(cardData)) {
        return;
      }

      // Set unique identifier to prevent duplicates
      cardDisplay.dataset.cardId = JSON.stringify(cardData);

      // Set title
      cardTitle.textContent = cardData.title || 'Appointment Preparation Guide';

      // Build card content
      let html = '';

      // Appointment details
      if (cardData.appointment_details) {
        html += '<div class="card-section">';
        html += '<h3>üìÖ Appointment Details</h3>';
        html += '<ul>';
        if (cardData.appointment_details.doctor) {
          html += `<li><strong>Doctor:</strong> ${cardData.appointment_details.doctor}</li>`;
        }
        if (cardData.appointment_details.reason) {
          html += `<li><strong>Reason:</strong> ${cardData.appointment_details.reason}</li>`;
        }
        if (cardData.appointment_details.timing) {
          html += `<li><strong>When:</strong> ${cardData.appointment_details.timing}</li>`;
        }
        html += '</ul>';
        html += '</div>';
      }

      // Preparation items
      if (cardData.preparation_items && cardData.preparation_items.length > 0) {
        html += '<div class="card-section">';
        html += '<h3>üìù What to Bring/Prepare</h3>';
        html += '<ul>';
        cardData.preparation_items.forEach(item => {
          html += `<li>${item}</li>`;
        });
        html += '</ul>';
        html += '</div>';
      }

      // Questions to ask
      if (cardData.questions_to_ask && cardData.questions_to_ask.length > 0) {
        html += '<div class="card-section">';
        html += '<h3>‚ùì Questions to Ask Your Doctor</h3>';
        html += '<ul>';
        cardData.questions_to_ask.forEach(question => {
          html += `<li>${question}</li>`;
        });
        html += '</ul>';
        html += '</div>';
      }

      // Follow-up actions
      if (cardData.follow_up_actions && cardData.follow_up_actions.length > 0) {
        html += '<div class="card-section">';
        html += '<h3>üìã After Your Appointment</h3>';
        html += '<ul>';
        cardData.follow_up_actions.forEach(action => {
          html += `<li>${action}</li>`;
        });
        html += '</ul>';
        html += '</div>';
      }

      // Use requestAnimationFrame to prevent visual flickering
      requestAnimationFrame(() => {
        cardContent.innerHTML = html;
        if (!cardDisplay.classList.contains('active')) {
          cardDisplay.classList.add('active');
          // Smooth fade-in effect
          cardDisplay.style.opacity = '0';
          cardDisplay.style.transform = 'translateY(10px)';
          setTimeout(() => {
            cardDisplay.style.transition = 'opacity 0.3s ease, transform 0.3s ease';
            cardDisplay.style.opacity = '1';
            cardDisplay.style.transform = 'translateY(0)';
          }, 10);
        }
      });
    }

    function sendTextMessage() {
      const input = document.getElementById('messageInput');
      const message = input.value.trim();
      
      if (message && socket && socket.readyState === WebSocket.OPEN) {
        const payload = {
          type: "text",
          text: message
        };
        
        socket.send(JSON.stringify(payload));
        ConversationLogger.userInput(message, 'text');
        addLog(`Sent: ${message}`, "sent");
        input.value = '';
        
        // Show thinking indicator for text messages too
        showThinkingIndicator();
      }
    }

    async function initAudioContext() {
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        
        // Load AudioWorklet for better audio playback
        try {
          await audioContext.audioWorklet.addModule('/static/audio-processor.js');
          workletNode = new AudioWorkletNode(audioContext, 'ring-buffer-processor');
          workletNode.connect(audioContext.destination);
        } catch (e) {
          console.warn("[Audio] WorkletNode unavailable, using fallback processor:", e);
        }
        
        addLog("Audio context initialized", "voice");
      } catch (e) {
        addLog(`Failed to initialize audio: ${e.message}`, "error");
      }
    }

    async function startVoice() {
      if (isRecording) return;
      
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 24000
          }
        });
        
        await audioContext.resume();
        source = audioContext.createMediaStreamSource(mediaStream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        
        processor.onaudioprocess = (event) => {
          if (socket && socket.readyState === WebSocket.OPEN) {
            const input = event.inputBuffer.getChannelData(0);
            const pcm = float32ToInt16(input);
            socket.send(pcm.buffer);
          }
        };
        
        source.connect(processor);
        processor.connect(audioContext.destination);
        
        isRecording = true;
        document.getElementById("startVoiceBtn").disabled = true;
        document.getElementById("stopVoiceBtn").disabled = false;
        
        addLog("üé§ Voice recording started", "voice");
        
      } catch (e) {
        addLog(`Failed to start voice: ${e.message}`, "error");
      }
    }

    function stopVoice() {
      if (!isRecording) return;
      
      if (processor) {
        processor.disconnect();
        processor = null;
      }
      
      if (source) {
        source.disconnect();
        source = null;
      }
      
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
      
      isRecording = false;
      document.getElementById("startVoiceBtn").disabled = false;
      document.getElementById("stopVoiceBtn").disabled = true;
      
      addLog("üõë Voice recording stopped", "voice");
      
      // Start thinking timer when user stops speaking
      startThinkingTimer();
    }

    function float32ToInt16(buffer) {
      const l = buffer.length;
      const buf = new Int16Array(l);
      for (let i = 0; i < l; i++) {
        buf[i] = Math.max(-1, Math.min(1, buffer[i])) * 0x7FFF;
      }
      return buf;
    }

    function base64ToArrayBuffer(base64) {
      const binaryString = atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    }

    async function playAudio(arrayBuffer) {
      try {
        if (!audioContext) {
          await initAudioContext();
        }
        
        // Convert Int16 PCM to Float32 for AudioWorklet (same as call-center project)
        const int16 = new Int16Array(arrayBuffer);
        const float32 = new Float32Array(int16.length);
        for (let i = 0; i < int16.length; i++) {
          float32[i] = int16[i] / (int16[i] < 0 ? 0x8000 : 0x7FFF);
        }
        
        // Send to AudioWorklet if available, otherwise fallback to direct playback
        if (workletNode) {
          workletNode.port.postMessage({ pcm: float32 });
        } else {
          // Fallback: create buffer source for direct playback
          const audioBuffer = audioContext.createBuffer(1, float32.length, audioContext.sampleRate);
          audioBuffer.getChannelData(0).set(float32);
          const source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          source.start();
        }
      } catch (e) {
        console.error("[Audio] Audio playback error:", e);
        addLog(`Audio playback error: ${e.message}`, "error");
      }
    }

    function showAudioIndicator() {
      const indicator = document.getElementById('audioIndicator');
      indicator.classList.add('active');
      setTimeout(() => {
        indicator.classList.remove('active');
      }, 2000);
    }

    function showThinkingIndicator() {
      const thinkingIndicator = document.getElementById('thinkingIndicator');
      thinkingIndicator.classList.add('active');
      addLog("ü§î AI is analyzing your request...", "voice");
    }

    function hideThinkingIndicator() {
      const thinkingIndicator = document.getElementById('thinkingIndicator');
      thinkingIndicator.classList.remove('active');
      if (thinkingTimeout) {
        clearTimeout(thinkingTimeout);
        thinkingTimeout = null;
      }
    }

    // Initialize marked library settings when page loads
    function initializeMarkdown() {
      if (typeof marked !== 'undefined') {
        marked.setOptions({
          breaks: true,
          sanitize: false,
          smartypants: true,
          gfm: true,
          renderer: new marked.Renderer()
        });
        
        // Custom renderer for better styling
        const renderer = new marked.Renderer();
        renderer.list = function(body, ordered) {
          const type = ordered ? 'ol' : 'ul';
          return `<${type} style="margin: 8px 0; padding-left: 20px;">${body}</${type}>`;
        };
        renderer.listitem = function(text) {
          return `<li style="margin: 3px 0; line-height: 1.4;">${text}</li>`;
        };
        
        marked.setOptions({ renderer });
        addLog("‚úÖ Enhanced Markdown formatting enabled", "info");
      } else {
        addLog("‚ö†Ô∏è Markdown library not loaded, using basic formatting", "info");
      }
    }

    function startThinkingTimer() {
      // Show thinking indicator after 1 second of no activity (user stopped speaking)
      if (thinkingTimeout) {
        clearTimeout(thinkingTimeout);
      }
      
      thinkingTimeout = setTimeout(() => {
        if (!isProcessingResponse) {
          showThinkingIndicator();
        }
      }, 1000);
    }

    function updateStreamingTranscript(text, isPartial = true) {
      const streamingTranscript = document.getElementById('streamingTranscript');
      
      if (!text || text.trim() === '') {
        hideStreamingTranscript();
        return;
      }
      
      // Format the transcript text with markdown
      const formattedText = formatConversationText(text);
      
      // Update the transcript content
      streamingTranscript.innerHTML = formattedText;
      
      // Show the element and update its state
      streamingTranscript.classList.add('active');
      
      if (isPartial) {
        streamingTranscript.classList.add('partial');
      } else {
        streamingTranscript.classList.remove('partial');
        // Hide after final transcript is shown for a moment
        setTimeout(() => {
          hideStreamingTranscript();
        }, 2000);
      }
    }

    function hideStreamingTranscript() {
      const streamingTranscript = document.getElementById('streamingTranscript');
      streamingTranscript.classList.remove('active', 'partial');
    }

    // Allow Enter key to send message in text mode
    document.getElementById('messageInput').addEventListener('keypress', (e) => {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    // Initialize the application
    document.addEventListener('DOMContentLoaded', function() {
      initializeMarkdown();
      setMode('voice');
    });
  </script>
</body>
</html>