<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice Multi-Agent Assistant - Healthcare Appointment Preparation</title>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <style>
    /* Fluent UI Design System */
    :root {
      --fluent-primary: #0078d4;
      --fluent-primary-hover: #106ebe;
      --fluent-primary-pressed: #005a9e;
      --fluent-neutral-10: #faf9f8;
      --fluent-neutral-20: #f3f2f1;
      --fluent-neutral-30: #edebe9;
      --fluent-neutral-40: #e1dfdd;
      --fluent-neutral-60: #c8c6c4;
      --fluent-neutral-90: #605e5c;
      --fluent-neutral-100: #484644;
      --fluent-neutral-140: #323130;
      --fluent-neutral-160: #201f1e;
      --fluent-success: #107c10;
      --fluent-warning: #ffaa44;
      --fluent-danger: #d83b01;
      --fluent-info: #8764b8;
      
      --fluent-shadow-2: 0 1px 2px rgba(0,0,0,0.14), 0 0px 2px rgba(0,0,0,0.12);
      --fluent-shadow-4: 0 2px 4px rgba(0,0,0,0.14), 0 0px 4px rgba(0,0,0,0.12);
      --fluent-shadow-8: 0 4px 8px rgba(0,0,0,0.14), 0 0px 8px rgba(0,0,0,0.12);
      --fluent-shadow-16: 0 8px 16px rgba(0,0,0,0.14), 0 0px 16px rgba(0,0,0,0.12);
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      font-family: 'Segoe UI', -apple-system, BlinkMacSystemFont, 'Roboto', sans-serif;
      background: var(--fluent-neutral-10);
      min-height: 100vh;
      color: var(--fluent-neutral-160);
      line-height: 1.4;
    }

    .app-header {
      background: white;
      border-bottom: 1px solid var(--fluent-neutral-40);
      padding: 16px 24px;
      box-shadow: var(--fluent-shadow-2);
    }

    .app-title {
      margin: 0;
      font-size: 20px;
      font-weight: 600;
      color: var(--fluent-neutral-160);
    }

    .app-subtitle {
      margin: 4px 0 0 0;
      font-size: 14px;
      color: var(--fluent-neutral-90);
      font-weight: 400;
    }

    .app-container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 24px;
      display: grid;
      grid-template-columns: 1fr;
      gap: 24px;
    }

    @media (min-width: 768px) {
      .app-container {
        grid-template-columns: 400px 1fr;
      }
    }

    .mode-selector {
      display: flex;
      background: white;
      border-radius: 4px;
      border: 1px solid var(--fluent-neutral-60);
      overflow: hidden;
      margin-bottom: 24px;
      box-shadow: var(--fluent-shadow-2);
    }

    .mode-btn {
      flex: 1;
      padding: 12px 16px;
      border: none;
      background: transparent;
      color: var(--fluent-neutral-90);
      font-weight: 400;
      font-size: 14px;
      cursor: pointer;
      transition: all 0.1s ease-in;
      border-right: 1px solid var(--fluent-neutral-40);
    }

    .mode-btn:last-child {
      border-right: none;
    }

    .mode-btn.active {
      background: var(--fluent-primary);
      color: white;
      font-weight: 600;
    }

    .mode-btn:hover:not(.active) {
      background: var(--fluent-neutral-20);
    }

    .mode-btn:active:not(.active) {
      background: var(--fluent-neutral-30);
    }

    .voice-only {
      display: none;
    }

    .voice-only.active {
      display: inline-block;
    }

    .control-panel {
      background: white;
      border-radius: 4px;
      border: 1px solid var(--fluent-neutral-40);
      padding: 20px;
      margin-bottom: 24px;
      box-shadow: var(--fluent-shadow-2);
    }

    .control-section {
      display: flex;
      gap: 8px;
      justify-content: center;
      align-items: center;
      margin-bottom: 16px;
      flex-wrap: wrap;
    }

    .control-section:last-child {
      margin-bottom: 0;
    }

    .fluent-button {
      padding: 8px 16px;
      font-size: 14px;
      font-weight: 400;
      border: 1px solid var(--fluent-neutral-60);
      border-radius: 4px;
      cursor: pointer;
      transition: all 0.1s ease-in;
      background: white;
      color: var(--fluent-neutral-160);
      min-width: 120px;
      text-align: center;
    }

    .fluent-button:hover {
      background: var(--fluent-neutral-20);
      border-color: var(--fluent-neutral-90);
    }

    .fluent-button:active {
      background: var(--fluent-neutral-30);
    }

    .fluent-button.primary {
      background: var(--fluent-primary);
      border-color: var(--fluent-primary);
      color: white;
    }

    .fluent-button.primary:hover {
      background: var(--fluent-primary-hover);
      border-color: var(--fluent-primary-hover);
    }

    .fluent-button.primary:active {
      background: var(--fluent-primary-pressed);
      border-color: var(--fluent-primary-pressed);
    }

    .fluent-button.danger {
      background: var(--fluent-danger);
      border-color: var(--fluent-danger);
      color: white;
    }

    .fluent-button.danger:hover {
      background: #c1360c;
      border-color: #c1360c;
    }

    .fluent-button.danger:active {
      background: #a12d06;
      border-color: #a12d06;
    }

    .fluent-button:disabled {
      background: var(--fluent-neutral-20);
      border-color: var(--fluent-neutral-40);
      color: var(--fluent-neutral-60);
      cursor: not-allowed;
    }

    .voice-controls {
      display: none;
    }

    .voice-controls.active {
      display: block;
    }

    /* Voice control buttons inherit fluent button styling */

    /* Text input panel removed - Voice-only mode */

    .input-row {
      display: flex;
      gap: 8px;
      align-items: flex-end;
    }

    .fluent-textbox {
      flex: 1;
      padding: 8px 12px;
      border: 1px solid var(--fluent-neutral-60);
      border-radius: 4px;
      font-size: 14px;
      font-family: inherit;
      background: white;
      color: var(--fluent-neutral-160);
      min-height: 20px;
      resize: vertical;
    }

    .fluent-textbox:focus {
      outline: none;
      border-color: var(--fluent-primary);
      box-shadow: inset 0 0 0 1px var(--fluent-primary);
    }

    .fluent-textbox::placeholder {
      color: var(--fluent-neutral-60);
    }

    .status-bar {
      background: white;
      border-radius: 4px;
      border: 1px solid var(--fluent-neutral-40);
      padding: 12px 16px;
      margin-bottom: 24px;
      box-shadow: var(--fluent-shadow-2);
    }

    .status-indicator {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 14px;
    }

    .status-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      flex-shrink: 0;
    }

    .status-indicator.connected .status-dot {
      background: var(--fluent-success);
    }

    .status-indicator.disconnected .status-dot {
      background: var(--fluent-danger);
    }

    .status-indicator.connected {
      color: var(--fluent-success);
    }

    .status-indicator.disconnected {
      color: var(--fluent-danger);
    }

    .info-card {
      background: white;
      border: 1px solid var(--fluent-neutral-40);
      border-radius: 4px;
      padding: 20px;
      margin-bottom: 24px;
      box-shadow: var(--fluent-shadow-2);
      display: none;
    }

    .info-card.active {
      display: block;
    }

    .info-card-title {
      font-size: 16px;
      font-weight: 600;
      color: var(--fluent-neutral-160);
      margin: 0 0 16px 0;
      padding-bottom: 8px;
      border-bottom: 1px solid var(--fluent-neutral-30);
    }

    .info-section {
      margin-bottom: 16px;
      padding: 12px 16px;
      background: var(--fluent-neutral-10);
      border-radius: 4px;
      border-left: 3px solid var(--fluent-primary);
    }

    .info-section:last-child {
      margin-bottom: 0;
    }

    .info-section h3 {
      margin: 0 0 8px 0;
      color: var(--fluent-neutral-160);
      font-size: 14px;
      font-weight: 600;
    }

    .info-section ul {
      margin: 0;
      padding-left: 20px;
    }

    .info-section li {
      margin: 4px 0;
      color: var(--fluent-neutral-90);
      font-size: 14px;
    }

    .conversation-log {
      background: white;
      border: 1px solid var(--fluent-neutral-40);
      border-radius: 4px;
      padding: 16px;
      height: 600px;
      max-height: calc(100vh - 200px);
      overflow: hidden;
      font-family: 'Segoe UI', sans-serif;
      font-size: 14px;
      box-shadow: var(--fluent-shadow-2);
      flex: 1;
      display: flex;
      flex-direction: column;
    }

    .log-header {
      font-size: 16px;
      font-weight: 600;
      color: var(--fluent-neutral-160);
      margin: 0 0 16px 0;
      padding-bottom: 8px;
      border-bottom: 1px solid var(--fluent-neutral-30);
      flex-shrink: 0;
    }

    .log-content {
      flex: 1;
      overflow-y: auto;
      overflow-x: hidden;
      padding-right: 8px;
      scroll-behavior: smooth;
      scrollbar-width: thin;
      scrollbar-color: var(--fluent-neutral-60) transparent;
    }

    .log-content::-webkit-scrollbar {
      width: 6px;
    }

    .log-content::-webkit-scrollbar-track {
      background: transparent;
    }

    .log-content::-webkit-scrollbar-thumb {
      background: var(--fluent-neutral-60);
      border-radius: 3px;
    }

    .log-content::-webkit-scrollbar-thumb:hover {
      background: var(--fluent-neutral-90);
    }

    .entry-highlight {
      background: var(--fluent-primary-10) !important;
      border-left: 3px solid var(--fluent-primary) !important;
      transform: translateX(0);
      transition: background-color 0.3s ease, border-left 0.3s ease, transform 0.3s ease;
    }

    .speech-focus {
      background: var(--fluent-accent-10) !important;
      border-left: 4px solid var(--fluent-accent) !important;
      box-shadow: 0 2px 8px rgba(0, 120, 212, 0.15) !important;
      animation: speechPulse 0.6s ease-out;
    }

    @keyframes speechPulse {
      0% {
        transform: translateX(-4px);
        opacity: 0.8;
      }
      50% {
        transform: translateX(2px);
        opacity: 1;
      }
      100% {
        transform: translateX(0);
        opacity: 1;
      }
    }

    .scroll-indicator {
      position: absolute;
      bottom: 24px;
      right: 24px;
      background: var(--fluent-primary);
      color: white;
      border: none;
      border-radius: 20px;
      padding: 8px 16px;
      font-size: 12px;
      font-weight: 500;
      box-shadow: var(--fluent-shadow-8);
      cursor: pointer;
      opacity: 0;
      transform: translateY(10px);
      transition: opacity 0.3s ease, transform 0.3s ease;
      z-index: 100;
    }

    .scroll-indicator.visible {
      opacity: 1;
      transform: translateY(0);
    }

    .scroll-indicator:hover {
      background: var(--fluent-primary-dark);
    }

    /* Enhanced conversation formatting */
    .log-entry {
      line-height: 1.5;
    }

    .log-entry strong {
      color: var(--fluent-neutral-160);
    }

    .log-entry .ai-header {
      font-weight: 600;
      font-size: 1.1em;
      margin: 16px 0 12px 0; /* Increased bottom margin for better spacing */
      color: var(--fluent-primary);
      border-bottom: 1px solid var(--fluent-neutral-30);
      padding-bottom: 4px;
      display: block;
    }

    /* Ensure headers have proper line breaks after them */
    .log-entry .ai-header + br,
    .log-entry div[style*="font-weight: 600"] + br {
      display: block;
      margin-bottom: 8px;
    }

    .log-entry .ai-list-item {
      margin: 6px 0;
      padding: 4px 0 4px 24px;
      position: relative;
      display: block;
      clear: both;
    }

    .log-entry .ai-list-number {
      position: absolute;
      left: 0;
      font-weight: 600;
      color: var(--fluent-primary);
    }

    .log-entry .ai-bullet {
      margin: 6px 0; /* Increased margin for better spacing */
      padding-left: 20px;
      position: relative;
      display: block;
      clear: both;
    }

    .log-entry .ai-bullet-icon {
      position: absolute;
      left: 4px;
      color: var(--fluent-primary);
    }

    /* Ensure proper spacing between headers and lists */
    .log-entry .ai-header + .ai-bullet,
    .log-entry .ai-header + .ai-list-item,
    .log-entry div[style*="font-weight: 600"] + .ai-bullet,
    .log-entry div[style*="font-weight: 600"] + .ai-list-item {
      margin-top: 8px;
    }

    .log-entry {
      margin: 12px 0;
      padding: 12px 16px;
      border-radius: 4px;
      border-left: 3px solid;
      line-height: 1.4;
      font-family: inherit;
    }

    .log-entry p {
      margin: 6px 0;
      line-height: 1.4;
    }

    .log-entry p:first-child {
      margin-top: 0;
    }

    .log-entry p:last-child {
      margin-bottom: 0;
    }

    .log-entry p:empty {
      display: none;
    }

    .log-entry ul {
      margin: 8px 0;
      padding-left: 20px;
    }

    .log-entry li {
      margin: 3px 0;
      line-height: 1.4;
    }

    .log-entry strong {
      font-weight: 600;
      color: var(--fluent-neutral-160);
    }
    .log-entry *:empty {
      display: none;
    }

    .log-sent {
      background: #f3f9ff;
      border-left-color: var(--fluent-primary);
      color: var(--fluent-neutral-140);
    }

    .log-received {
      background: #f3fff8;
      border-left-color: var(--fluent-success);
      color: var(--fluent-neutral-140);
    }

    .log-voice {
      background: #faf7ff;
      border-left-color: var(--fluent-info);
      color: var(--fluent-neutral-140);
    }

    .log-error {
      background: #fff5f5;
      border-left-color: var(--fluent-danger);
      color: var(--fluent-neutral-140);
    }



    .processing-status {
      display: none;
      padding: 12px 16px;
      margin: 12px 0;
      background: white;
      border: 1px solid var(--fluent-neutral-40);
      border-radius: 4px;
      box-shadow: var(--fluent-shadow-2);
      color: var(--fluent-neutral-90);
      font-size: 14px;
      text-align: center;
    }

    .processing-status.active {
      display: block;
    }



    .conversation-panel {
      grid-column: 1 / -1;
      min-height: calc(100vh - 160px);
      display: flex;
      flex-direction: column;
      position: relative;
    }

    @media (min-width: 768px) {
      .conversation-panel {
        grid-column: 2;
        grid-row: 1;
      }
    }

    /* Removed old thinking indicator styles */

    .streaming-transcript {
      background: white;
      border: 1px solid var(--fluent-neutral-40);
      border-radius: 4px;
      padding: 12px 16px;
      margin: 12px 0;
      font-family: 'Segoe UI', sans-serif;
      color: var(--fluent-neutral-90);
      font-size: 14px;
      display: none;
      box-shadow: var(--fluent-shadow-2);
    }

    .streaming-transcript.active {
      display: block;
    }

    .streaming-transcript::before {
      content: "AI Speaking: ";
      font-weight: 600;
      color: #2f855a;
    }

    .streaming-transcript.partial::after {
      content: " â–‹";
      color: #68d391;
      animation: blink 1s infinite;
    }

    /* Removed thinking dots animation */

    /* Removed animations for professional appearance */

    .main-panel {
      display: flex;
      flex-direction: column;
      height: fit-content;
    }

    @media (min-width: 768px) {
      .main-panel {
        max-width: 380px;
        padding-right: 12px;
      }
    }

  </style>
</head>
<body>
  <div class="app-header">
    <h1 class="app-title">Voice Multi-Agent Assistant</h1>
    <p class="app-subtitle">Healthcare Appointment Preparation</p>
  </div>

  <div class="app-container">
    <div class="main-panel">
      <!-- Voice Mode - Single Mode -->
      <div class="mode-selector">
        <button class="mode-btn active" id="voiceModeBtn" disabled>
          Voice Mode
        </button>
      </div>

      <!-- Connection Controls -->
      <div class="control-panel">
        <div class="control-section">
          <button id="connectBtn" onclick="connectWebSocket()" class="fluent-button primary">
            Connect to Assistant
          </button>
          <button id="disconnectBtn" onclick="disconnectWebSocket()" disabled class="fluent-button danger">
            Disconnect
          </button>
        </div>

        <!-- Voice Controls -->
        <div class="voice-controls" id="voiceControls">
          <div class="control-section">
            <button id="startVoiceBtn" onclick="startVoice()" disabled class="fluent-button primary">
              Start Speaking
            </button>
            <button id="stopVoiceBtn" onclick="stopVoice()" disabled class="fluent-button">
              Stop Speaking
            </button>
          </div>
        </div>
      </div>

      <!-- Status Display -->
      <div class="status-bar">
        <div class="status-indicator disconnected" id="status">
          <div class="status-dot"></div>
          <span>Disconnected - Click "Connect to Assistant" to start</span>
        </div>
      </div>



      <!-- AI Processing Status -->
      <div class="processing-status" id="thinkingIndicator">
        AI Assistant is processing your request...
      </div>

      <!-- Real-time Transcript -->
      <div class="processing-status" id="streamingTranscript">
      </div>
    </div>

    <div class="conversation-panel">
      <div class="conversation-log" id="logs">
        <h3 class="log-header">Conversation History</h3>
        <div class="log-content">
          <div class="log-entry log-received">
            <p><strong>Welcome!</strong> This is the Voice Multi-Agent Assistant for healthcare appointment preparation.</p>
            <ul>
              <li><strong>Voice Mode:</strong> Speak about your medical appointments and get personalized guidance</li>
              <li><strong>Text Mode:</strong> Type your appointment details for structured responses</li>
            </ul>
            <p><strong>Example:</strong> "I have an appointment with Dr. Smith next week for chest pain"</p>
          </div>
        </div>
      </div>
      <button class="scroll-indicator" id="scrollIndicator" onclick="scrollToBottom()">
        New messages â†“
      </button>
    </div>

    <!-- Information Card Display -->
    <div id="cardDisplay" class="info-card">
      <h3 id="cardTitle" class="info-card-title">Appointment Preparation Guide</h3>
      <div id="cardContent" class="info-card-content"></div>
    </div>
  </div>

  <script>
    let socket;
    let currentMode = 'voice';
    let mediaStream;
    let audioContext;
    let source;
    let processor;
    let isRecording = false;
    let workletNode;
    let readyMessageShown = false;
    let isProcessingResponse = false;
    let responseBuffer = null;
    let lastTranscriptTime = 0;
    let thinkingTimeout = null;
    let streamingTranscriptElement = null;

    // Professional logging utility
    const ConversationLogger = {
      logPrefix: '[Conversation]',
      
      userInput: function(text, type = 'voice') {
        console.log(`${this.logPrefix} User input received:`, {
          type: type,
          content: text.substring(0, 100) + (text.length > 100 ? '...' : ''),
          length: text.length,
          timestamp: new Date().toISOString()
        });
      },
      
      agentResponse: function(response, hasCard = false) {
        console.log(`${this.logPrefix} Agent response:`, {
          spoken_length: response.length,
          has_card: hasCard,
          timestamp: new Date().toISOString()
        });
      },
      
      cardDisplayed: function(cardData) {
        console.log(`${this.logPrefix} Card displayed:`, {
          title: cardData.title,
          preparation_items: cardData.preparation_items?.length || 0,
          questions: cardData.questions_to_ask?.length || 0,
          timestamp: new Date().toISOString()
        });
      },
      
      flowState: function(state, details = {}) {
        console.log(`${this.logPrefix} Flow state:`, {
          state: state,
          ...details,
          timestamp: new Date().toISOString()
        });
      },

      error: function(component, error) {
        console.error(`${this.logPrefix} Error in ${component}:`, error);
      }
    };

    function setMode(mode) {
      // Force voice mode only
      currentMode = 'voice';
      
      // Voice controls are always active
      document.getElementById('voiceControls').classList.add('active');
    }

    function addLog(message, type = 'info') {
      const logs = document.querySelector('.log-content');
      const entry = document.createElement('div');
      entry.className = `log-entry log-${type}`;
      
      // Debug logging to catch object issues
      if (typeof message === 'object') {
        console.warn('[AddLog] Received object instead of string:', message);
        message = JSON.stringify(message, null, 2);
      }
      if (typeof message !== 'string') {
        console.warn('[AddLog] Converting non-string message:', typeof message, message);
        message = String(message);
      }
      
      // Extract the actual content after emoji/prefix for AI responses
      let displayMessage = message;
      let actualContent = message;
      
      // For AI responses, separate the prefix from the content and log professionally
      if (message.includes('ðŸ¤– AI Response: ') || message.includes('AI Response: ') || message.includes('ðŸ¤– ')) {
        let parts;
        if (message.includes('ðŸ¤– ')) {
          parts = message.split('ðŸ¤– ');
          displayMessage = 'ðŸ¤– ';
        } else {
          parts = message.split(/ðŸ¤– AI Response: |AI Response: /);
          displayMessage = 'ðŸ¤– ';
        }
        
        if (parts.length > 1) {
          actualContent = parts[1];
          ConversationLogger.agentResponse(actualContent);
        }
      }
      
      // Format only the actual content, not the emoji/prefix
      const formattedContent = actualContent === message ? 
        formatConversationText(message) : 
        displayMessage + formatConversationText(actualContent);
      
      console.log('[AddLog] Formatted content type:', typeof formattedContent);
      console.log('[AddLog] Formatted content preview:', 
        typeof formattedContent === 'string' ? 
        formattedContent.substring(0, 200) + '...' : 
        formattedContent);
      
      entry.innerHTML = `<strong>${new Date().toLocaleTimeString()}</strong>: ${formattedContent}`;
      
      // Use requestAnimationFrame to batch DOM updates and reduce flickering
      requestAnimationFrame(() => {
        logs.appendChild(entry);
        
        // Limit log entries to prevent performance issues
        const entries = logs.querySelectorAll('.log-entry');
        if (entries.length > 50) {
          entries[0].remove();
        }
        
        // Direct auto-scroll to any new content
        scrollToLatestEntry(logs, entry);
        
        // For critical content (AI responses), add extra immediate scroll
        if (type === 'received' && (message.includes('ðŸ¤–') || message.includes('AI Response'))) {
          setTimeout(() => {
            logs.scrollTo({
              top: logs.scrollHeight,
              behavior: 'auto' // Instant scroll for AI responses
            });
          }, 200);
        }
      });
    }

    // Direct auto-scroll function - always scrolls to new content immediately
    function scrollToLatestEntry(container, newEntry) {
      // Always scroll to new content - no conditions or user position checks
      const isSpeechConversation = isSpeechRelatedMessage(newEntry);
      
      // Add visual highlight to new entry
      newEntry.classList.add('entry-highlight');
      if (isSpeechConversation) {
        newEntry.classList.add('speech-focus');
      }
      
      // Mark auto-scroll in progress
      window.autoScrollInProgress = true;
      
      // Immediate scroll to new content - no delays
      setTimeout(() => {
        // Direct scroll to bottom to show latest content
        container.scrollTo({
          top: container.scrollHeight,
          behavior: 'smooth'
        });
        
        // Clear auto-scroll flag after animation completes
        setTimeout(() => {
          window.autoScrollInProgress = false;
        }, 500);
        
        // Remove highlight after animation
        setTimeout(() => {
          newEntry.classList.remove('entry-highlight');
          newEntry.classList.remove('speech-focus');
        }, 2000);
      }, 10); // Minimal delay just to ensure DOM is updated
    }

    // Check if a message is speech-related for enhanced focus
    function isSpeechRelatedMessage(entry) {
      const entryText = entry.textContent || entry.innerHTML || '';
      const speechKeywords = [
        'Voice recording started',
        'Voice recording stopped', 
        'Processing voice input',
        'AI Response:',
        'ðŸ¤–',
        'Appointment Preparation',
        'speak',
        'listening'
      ];
      
      return speechKeywords.some(keyword => 
        entryText.toLowerCase().includes(keyword.toLowerCase())
      );
    }

    // Check if there's active conversation happening - enhanced for speech focus
    function isActiveConversation() {
      // Consider conversation active if there was recent activity (within last 15 seconds for speech)
      const now = Date.now();
      const speechActivityThreshold = 15000; // 15 seconds for speech conversations
      const generalActivityThreshold = 8000;  // 8 seconds for other activities
      
      // Enhanced speech detection
      const isVoiceRecording = isRecording;
      const isSpeakingActive = document.getElementById('startSpeaking')?.textContent === 'Stop Speaking';
      const isThinking = document.querySelector('.thinking-indicator')?.style.display !== 'none';
      
      // Use longer threshold for speech-related activities
      const activityThreshold = (isVoiceRecording || isSpeakingActive) ? 
                               speechActivityThreshold : generalActivityThreshold;
      
      // Check if websocket is active or there are ongoing speech operations
      return wsConnected || 
             isVoiceRecording ||
             isSpeakingActive ||
             isThinking ||
             (window.lastActivityTime && (now - window.lastActivityTime) < activityThreshold);
    }

    // Track activity time for smart scrolling
    function trackActivity() {
      window.lastActivityTime = Date.now();
    }

    // Process AI response content to handle structured data
    function processAIResponse(responseData) {
      console.log('[ProcessAI] Processing response:', responseData);
      console.log('[ProcessAI] Response type:', typeof responseData);
      console.log('[ProcessAI] Response keys:', Object.keys(responseData || {}));
      
      let content = '';
      
      // Try different fields that might contain the response
      if (responseData.spoken_response) {
        content = responseData.spoken_response;
        console.log('[ProcessAI] Using spoken_response:', typeof content);
      } else if (responseData.text) {
        content = responseData.text;
        console.log('[ProcessAI] Using text:', typeof content);
      } else if (responseData.content) {
        content = responseData.content;
        console.log('[ProcessAI] Using content:', typeof content);
      } else if (responseData.message) {
        content = responseData.message;
        console.log('[ProcessAI] Using message:', typeof content);
      } else if (typeof responseData === 'string') {
        content = responseData;
        console.log('[ProcessAI] Using responseData as string');
      }
      
      // Ensure we have a string
      if (typeof content !== 'string') {
        console.warn('[ProcessAI] Content is not a string:', typeof content, content);
        if (content && typeof content === 'object') {
          console.log('[ProcessAI] Content object keys:', Object.keys(content));
          // Try to extract text from common object structures
          if (content.text) content = content.text;
          else if (content.content) content = content.content;
          else {
            console.warn('[ProcessAI] Converting object to JSON string');
            content = JSON.stringify(content, null, 2);
          }
        } else {
          content = String(content || '');
        }
      }
      
      console.log('[ProcessAI] Final content type:', typeof content);
      console.log('[ProcessAI] Final content preview:', content.substring(0, 200) + '...');
      return content.trim();
    }

    // Scroll to bottom function for the indicator button
    function scrollToBottom() {
      const logContent = document.querySelector('.log-content');
      if (logContent) {
        logContent.scrollTo({
          top: logContent.scrollHeight,
          behavior: 'smooth'
        });
      }
    }

    // Monitor scroll position and show/hide indicator (minimal use since auto-scroll is always active)
    function setupScrollIndicator() {
      const logContent = document.querySelector('.log-content');
      const scrollIndicator = document.getElementById('scrollIndicator');
      
      if (!logContent || !scrollIndicator) return;
      
      logContent.addEventListener('scroll', () => {
        const isNearBottom = logContent.scrollHeight - logContent.scrollTop - logContent.clientHeight < 100;
        
        if (isNearBottom) {
          scrollIndicator.classList.remove('visible');
        } else {
          // Only show indicator if user manually scrolled up AND there's very recent activity
          const hasVeryRecentActivity = window.lastActivityTime && 
                                       (Date.now() - window.lastActivityTime) < 5000; // 5 seconds only
          // Only show if user actively scrolled up recently (not auto-scroll)
          if (hasVeryRecentActivity && !window.autoScrollInProgress) {
            scrollIndicator.classList.add('visible');
          }
        }
      });
    }

    // Initialize scroll indicator when page loads
    document.addEventListener('DOMContentLoaded', () => {
      setupScrollIndicator();
    });

    function formatConversationText(text) {
      // Ensure we have a string and handle potential objects
      if (!text) return '';
      if (typeof text === 'object') {
        console.warn('[Format] Received object instead of string:', text);
        // Try to extract meaningful content from object
        if (text.text) return formatConversationText(text.text);
        if (text.content) return formatConversationText(text.content);
        if (text.message) return formatConversationText(text.message);
        // Convert to string as fallback
        text = JSON.stringify(text, null, 2);
      }
      if (typeof text !== 'string') {
        console.warn('[Format] Converting non-string to string:', typeof text, text);
        text = String(text);
      }
      
      // Use safe HTML formatting that won't create objects
      try {
        // Clean up the text first
        let cleaned = text
          .replace(/\r\n/g, '\n')  // Normalize line endings
          .replace(/\n\s*\n\s*\n/g, '\n\n')  // Remove triple+ newlines
          .trim();
        
        // Process text line by line for better header-bullet spacing
        let lines = cleaned.split('\n');
        let processedLines = [];
        
        for (let i = 0; i < lines.length; i++) {
          let line = lines[i].trim();
          let nextLine = i + 1 < lines.length ? lines[i + 1].trim() : '';
          
          // Process headers (including bold headers)
          if (line.match(/^### /)) {
            let headerText = line.replace(/^### /, '');
            // Handle bold formatting in headers
            headerText = headerText.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            processedLines.push(`<div class="ai-header">${headerText}</div>`);
            // Add spacing if next line is a bullet or numbered list
            if (nextLine.match(/^[\*\-â€¢] /) || nextLine.match(/^\d+\. /)) {
              processedLines.push('<br>');
            }
          } else if (line.match(/^## /)) {
            let headerText = line.replace(/^## /, '');
            // Handle bold formatting in headers
            headerText = headerText.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            processedLines.push(`<div style="font-weight: 600; font-size: 1.2em; margin: 18px 0 10px 0; color: var(--fluent-primary);">${headerText}</div>`);
            // Add spacing if next line is a bullet or numbered list
            if (nextLine.match(/^[\*\-â€¢] /) || nextLine.match(/^\d+\. /)) {
              processedLines.push('<br>');
            }
          } else if (line.match(/^# /)) {
            let headerText = line.replace(/^# /, '');
            // Handle bold formatting in headers
            headerText = headerText.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            processedLines.push(`<div style="font-weight: 600; font-size: 1.3em; margin: 20px 0 12px 0; color: var(--fluent-primary);">${headerText}</div>`);
            // Add spacing if next line is a bullet or numbered list
            if (nextLine.match(/^[\*\-â€¢] /) || nextLine.match(/^\d+\. /)) {
              processedLines.push('<br>');
            }
          }
          // Detect bold text as headers (when it starts with ** and ends with **:)
          else if (line.match(/^\*\*(.+?)\*\*:?\s*$/)) {
            let match = line.match(/^\*\*(.+?)\*\*:?\s*$/);
            let headerText = match[1];
            processedLines.push(`<div class="ai-header"><strong>${headerText}</strong></div>`);
            // Add spacing if next line is a bullet or numbered list
            if (nextLine.match(/^[\*\-â€¢] /) || nextLine.match(/^\d+\. /)) {
              processedLines.push('<br>');
            }
          }
          // Process numbered lists
          else if (line.match(/^(\d+)\.\s*(.+)$/)) {
            let match = line.match(/^(\d+)\.\s*(.+)$/);
            let itemText = match[2].replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            processedLines.push(`<div class="ai-list-item"><span class="ai-list-number">${match[1]}.</span>${itemText}</div>`);
          }
          // Process bullet lists
          else if (line.match(/^[\*\-â€¢]\s*(.+)$/)) {
            let match = line.match(/^[\*\-â€¢]\s*(.+)$/);
            let itemText = match[1].replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            processedLines.push(`<div class="ai-bullet"><span class="ai-bullet-icon">â€¢</span>${itemText}</div>`);
          }
          // Regular text lines
          else if (line) {
            // Apply bold formatting to regular lines
            let formattedLine = line.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            processedLines.push(formattedLine);
          }
          // Empty lines for spacing
          else {
            processedLines.push('<div style="margin: 12px 0;"></div>');
          }
        }
        
        let formatted = processedLines.join('<br>');
        
        // Ensure result is a string
        if (typeof formatted !== 'string') {
          formatted = String(formatted);
        }
        
        return formatted;
        
      } catch (e) {
        // Fallback to plain text with line breaks
        return text.replace(/\n/g, '<br>') || '';
      }
      
      // Fallback: Basic formatting (original implementation)
      let cleaned = text
        .replace(/\r\n/g, '\n')
        .replace(/\n\s*\n\s*\n/g, '\n\n')
        .trim();
      
      // Handle bold text formatting (**text** to <strong>text</strong>)
      cleaned = cleaned.replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>');
      
      // Split into sections for better processing
      let sections = cleaned.split(/\n\s*\n/);
      let formattedSections = [];
      
      for (let section of sections) {
        if (!section.trim()) continue;
        
        // Check if this section contains bullet points
        if (section.includes('\nâ€¢ ') || section.includes('\n* ') || section.includes('\n- ')) {
          let lines = section.split('\n');
          let beforeList = [];
          let listItems = [];
          let inList = false;
          
          for (let line of lines) {
            line = line.trim();
            if (!line) continue;
            
            if (line.startsWith('â€¢ ') || line.startsWith('* ') || line.startsWith('- ')) {
              inList = true;
              let itemText = line.replace(/^[â€¢\*\-]\s*/, '');
              listItems.push(`<li>${itemText}</li>`);
            } else if (!inList) {
              beforeList.push(line);
            } else {
              if (line.startsWith('â€¢ ') || line.startsWith('* ') || line.startsWith('- ')) {
                let itemText = line.replace(/^[â€¢\*\-]\s*/, '');
                listItems.push(`<li>${itemText}</li>`);
              } else {
                if (listItems.length > 0) {
                  formattedSections.push(
                    (beforeList.length > 0 ? `<p>${beforeList.join(' ')}</p>` : '') +
                    `<ul>${listItems.join('')}</ul>`
                  );
                  beforeList = [line];
                  listItems = [];
                  inList = false;
                }
              }
            }
          }
          
          let result = '';
          if (beforeList.length > 0) {
            result += `<p>${beforeList.join(' ')}</p>`;
          }
          if (listItems.length > 0) {
            result += `<ul>${listItems.join('')}</ul>`;
          }
          
          if (result) formattedSections.push(result);
          
        } else {
          formattedSections.push(`<p>${section.trim()}</p>`);
        }
      }
      
      return formattedSections.join('');
    }

    function updateStatus(text, connected) {
      const status = document.getElementById('status');
      const statusText = status.querySelector('span');
      if (statusText) {
        statusText.textContent = text;
      }
      status.className = `status-indicator ${connected ? 'connected' : 'disconnected'}`;
    }

    function connectWebSocket() {
      const wsProtocol = window.location.protocol === "https:" ? "wss" : "ws";
      const wsHost = window.location.host;
      const endpoint = '/ws/voice'; // Always use voice endpoint
      
      socket = new WebSocket(`${wsProtocol}://${wsHost}${endpoint}`);
      socket.binaryType = "arraybuffer";

      socket.onopen = () => {
        addLog(`Connected to VOICE endpoint`, "received");
        updateStatus(`Connected in VOICE mode`, true);

        document.getElementById("connectBtn").disabled = true;
        document.getElementById("disconnectBtn").disabled = false;
        
        // Always enable voice controls since we're voice-only
        document.getElementById("startVoiceBtn").disabled = false;
        initAudioContext();
      };

      socket.onmessage = async (event) => {
        trackActivity(); // Track AI activity for smart scrolling
        
        if (event.data instanceof ArrayBuffer) {
          // Handle binary audio data (prioritize this like call-center project)
          try {
            hideThinkingIndicator(); // Hide thinking indicator when AI starts speaking
            await playAudio(event.data);
            showAudioIndicator();
          } catch (e) {
            console.error("[Audio] Playback failed:", e);
            addLog(`Audio playback error: ${e.message}`, "error");
          }
        } else if (typeof event.data === "string") {
          try {
            const data = JSON.parse(event.data);
            
            // Debug logging for all incoming messages
            console.log('[WebSocket] Received message:', {
              type: data?.type,
              kind: data?.Kind,
              hasText: !!data?.text,
              hasSpokenResponse: !!data?.spoken_response,
              hasCardData: !!data?.card_data,
              textLength: data?.text?.length || 0,
              keys: Object.keys(data)
            });
            
            // Handle JSON messages for transcription, stop audio, etc.
            if (data.Kind === "StopAudio") {
              addLog("ðŸ›‘ Audio stopped", "voice");
              // Stop any ongoing audio playback
              if (workletNode) {
                workletNode.port.postMessage({ clear: true });
              }
            } else if (data.Kind === "Transcription") {
              // Log AI response transcription correctly
              ConversationLogger.agentResponse(data.Text);
              addLog(`ðŸ¤– ${data.Text}`, "received");
            } else if (data.Kind === "UserTranscription") {
              // Log user speech transcription
              ConversationLogger.userInput(data.Text, 'voice');
              addLog(`ðŸŽ¤ You said: ${data.Text}`, "sent");
            } else if (data.Kind === "AudioData" && data.AudioData && data.AudioData.Data) {
              // Fallback: Decode base64 audio data (should not happen with raw_audio=True)
              const base64Audio = data.AudioData.Data;
              const audioBytes = base64ToArrayBuffer(base64Audio);
              await playAudio(audioBytes);
              showAudioIndicator();
            } else {
              // Handle regular text messages
              handleTextMessage(data);
            }
          } catch (e) {
            addLog(`Raw message: ${event.data}`, "received");
          }
        } else {
          console.log("[WebSocket] Unknown message type received:", {
            type: typeof event.data,
            data: event.data,
            timestamp: new Date().toISOString()
          });
        }
      };

      socket.onclose = () => {
        addLog("Disconnected from AI Assistant", "info");
        updateStatus("Disconnected", false);

        document.getElementById("connectBtn").disabled = false;
        document.getElementById("disconnectBtn").disabled = true;
        document.getElementById("startVoiceBtn").disabled = true;
        document.getElementById("stopVoiceBtn").disabled = true;
        readyMessageShown = false; // Reset flag for next connection
        
        // Clean up indicators
        hideThinkingIndicator();
        hideStreamingTranscript();
      };

      socket.onerror = (err) => {
        addLog("WebSocket connection error", "error");

        console.error("[WebSocket] Connection error:", err);
      };
    }

    function disconnectWebSocket() {
      if (isRecording) {
        stopVoice();
      }
      if (socket) {
        socket.close();
      }
    }

    function handleTextMessage(data) {
      const type = data.type || 'unknown';
      console.log('[WebSocket] Message received:', { 
        type: type, 
        session: data.session_id || 'unknown',
        keys: Object.keys(data),
        timestamp: new Date().toISOString()
      });
      
      switch (type) {
        case 'ready':
          if (!readyMessageShown) {
            addLog(`${data.text}`, "received");

            readyMessageShown = true;
          }
          break;
        case 'orchestration_response':
          // Handle multi-agent response - buffer it to prevent flickering
          console.log('[Debug] Orchestration response received:', data);

          hideThinkingIndicator(); // Hide thinking indicator when response starts
          trackActivity(); // Track AI response activity for enhanced scrolling
          isProcessingResponse = true;
          responseBuffer = data;
          
          // Delay processing slightly to avoid flickering with real-time transcripts
          setTimeout(() => {
            if (responseBuffer) {
              // Process the complete AI response using our robust handler
              const fullResponse = processAIResponse(responseBuffer);
              
              // Log the complete response if we have it
              if (fullResponse) {
                console.log('[Debug] Adding processed AI response:', fullResponse);
                trackActivity(); // Track again when actually displaying the response
                addLog(`ðŸ¤– ${fullResponse}`, "received");
                
                // Ensure immediate focus on AI responses in speech conversations
                setTimeout(() => {
                  const logContent = document.querySelector('.log-content');
                  if (logContent) {
                    logContent.scrollTo({
                      top: logContent.scrollHeight,
                      behavior: 'smooth'
                    });
                  }
                }, 50);
              }
              
              // Handle card data separately if present
              if (responseBuffer.card_data) {
                displayCard(responseBuffer.card_data);
                // Don't duplicate card content in logs since main response should include it
              }
            }
            isProcessingResponse = false;
            responseBuffer = null;
          }, 100); // Small delay to batch updates and reduce flickering
          break;
        case 'card':
          // Handle card data from voice orchestration
          if (data.payload && !isProcessingResponse) {
            displayCard(data.payload);
            // Log card display professionally with detailed content
            if (!document.getElementById('cardDisplay').classList.contains('active')) {
              ConversationLogger.cardDisplayed(data.payload);
              const cardContent = formatCardDataForLog(data.payload);
              if (cardContent) {
                addLog(`Appointment Preparation Details:\n\n${cardContent}`, "received");
              } else {
                addLog(`Generated appointment preparation checklist`, "received");
              }
            }
          }
          break;
        case 'ai_response':
          // Log AI responses immediately in conversation log
          const aiResponseContent = processAIResponse(data);
          if (aiResponseContent) {
            addLog(`ðŸ¤– ${aiResponseContent}`, "received");
          }
          break;
        case 'echo':
          addLog(`Echo: ${data.text.replace('Echo: ', '')}`, "received");
          break;
        case 'Transcription':
          // Handle streaming transcription for real-time feedback
          hideThinkingIndicator(); // Hide thinking when transcription starts
          
          if (data.text && data.text.trim()) {
            // Check if this is a partial or final transcript
            const isPartial = data.partial !== false; // Default to partial unless explicitly final
            const transcriptText = data.text.trim();
            
            // Update or create streaming transcript display
            updateStreamingTranscript(transcriptText, isPartial);
            
            // Only log final transcripts to avoid spam
            if (!isPartial) {
              // Log AI response transcription correctly
              ConversationLogger.agentResponse(transcriptText);
              addLog(`ðŸ¤– ${transcriptText}`, "received");
            }
          }
          break;
        case 'error':
          addLog(`âŒ Error: ${data.text}`, "error");
          break;
        default:
          // Reduce frequency of unknown message logging to prevent spam
          if (!isProcessingResponse) {
            const text = data.text || JSON.stringify(data);
            addLog(`ðŸ“¨ ${type}: ${text}`, "received");
          }
      }
    }

    function formatCardDataForLog(cardData) {
      if (!cardData) return '';
      
      let logContent = '';
      
      // Appointment details
      if (cardData.appointment_details) {
        logContent += '**Appointment Details**\n';
        if (cardData.appointment_details.doctor) {
          logContent += `â€¢ **Doctor:** ${cardData.appointment_details.doctor}\n`;
        }
        if (cardData.appointment_details.reason) {
          logContent += `â€¢ **Reason:** ${cardData.appointment_details.reason}\n`;
        }
        if (cardData.appointment_details.timing) {
          logContent += `â€¢ **When:** ${cardData.appointment_details.timing}\n`;
        }
        logContent += '\n';
      }

      // Preparation items
      if (cardData.preparation_items && cardData.preparation_items.length > 0) {
        logContent += '**Documents to Bring**\n';
        cardData.preparation_items.forEach(item => {
          logContent += `â€¢ ${item}\n`;
        });
        logContent += '\n';
      }

      // Questions to ask
      if (cardData.questions_to_ask && cardData.questions_to_ask.length > 0) {
        logContent += '**Questions to Ask Your Doctor**\n';
        cardData.questions_to_ask.forEach(question => {
          logContent += `â€¢ ${question}\n`;
        });
        logContent += '\n';
      }

      // Post-appointment notes
      if (cardData.post_appointment_notes && cardData.post_appointment_notes.length > 0) {
        logContent += '**After Your Appointment**\n';
        cardData.post_appointment_notes.forEach(note => {
          logContent += `â€¢ ${note}\n`;
        });
        logContent += '\n';
      }

      return logContent.trim();
    }

    function displayCard(cardData) {
      const cardDisplay = document.getElementById('cardDisplay');
      const cardTitle = document.getElementById('cardTitle');
      const cardContent = document.getElementById('cardContent');

      // Prevent duplicate card displays
      if (cardDisplay.classList.contains('active') && cardDisplay.dataset.cardId === JSON.stringify(cardData)) {
        return;
      }

      // Set unique identifier to prevent duplicates
      cardDisplay.dataset.cardId = JSON.stringify(cardData);

      // Set title
      cardTitle.textContent = cardData.title || 'Appointment Preparation Guide';

      // Build card content
      let html = '';

      // Appointment details
      if (cardData.appointment_details) {
        html += '<div class="info-section">';
        html += '<h3>Appointment Details</h3>';
        html += '<ul>';
        if (cardData.appointment_details.doctor) {
          html += `<li><strong>Doctor:</strong> ${cardData.appointment_details.doctor}</li>`;
        }
        if (cardData.appointment_details.reason) {
          html += `<li><strong>Reason:</strong> ${cardData.appointment_details.reason}</li>`;
        }
        if (cardData.appointment_details.timing) {
          html += `<li><strong>When:</strong> ${cardData.appointment_details.timing}</li>`;
        }
        html += '</ul>';
        html += '</div>';
      }

      // Preparation items
      if (cardData.preparation_items && cardData.preparation_items.length > 0) {
        html += '<div class="info-section">';
        html += '<h3>What to Bring/Prepare</h3>';
        html += '<ul>';
        cardData.preparation_items.forEach(item => {
          html += `<li>${item}</li>`;
        });
        html += '</ul>';
        html += '</div>';
      }

      // Questions to ask
      if (cardData.questions_to_ask && cardData.questions_to_ask.length > 0) {
        html += '<div class="info-section">';
        html += '<h3>Questions to Ask Your Doctor</h3>';
        html += '<ul>';
        cardData.questions_to_ask.forEach(question => {
          html += `<li>${question}</li>`;
        });
        html += '</ul>';
        html += '</div>';
      }

      // Follow-up actions
      if (cardData.follow_up_actions && cardData.follow_up_actions.length > 0) {
        html += '<div class="info-section">';
        html += '<h3>After Your Appointment</h3>';
        html += '<ul>';
        cardData.follow_up_actions.forEach(action => {
          html += `<li>${action}</li>`;
        });
        html += '</ul>';
        html += '</div>';
      }

      // Use requestAnimationFrame to prevent visual flickering
      requestAnimationFrame(() => {
        cardContent.innerHTML = html;
        if (!cardDisplay.classList.contains('active')) {
          cardDisplay.classList.add('active');
          // Smooth fade-in effect
          cardDisplay.style.opacity = '0';
          cardDisplay.style.transform = 'translateY(10px)';
          setTimeout(() => {
            cardDisplay.style.transition = 'opacity 0.3s ease, transform 0.3s ease';
            cardDisplay.style.opacity = '1';
            cardDisplay.style.transform = 'translateY(0)';
          }, 10);
        }
      });
    }

    async function initAudioContext() {
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        
        // Load AudioWorklet for better audio playback
        try {
          await audioContext.audioWorklet.addModule('/static/audio-processor.js');
          workletNode = new AudioWorkletNode(audioContext, 'ring-buffer-processor');
          workletNode.connect(audioContext.destination);
        } catch (e) {
          console.warn("[Audio] WorkletNode unavailable, using fallback processor:", e);
        }
        
        addLog("Audio context initialized", "voice");
      } catch (e) {
        addLog(`Failed to initialize audio: ${e.message}`, "error");
      }
    }

    async function startVoice() {
      if (isRecording) return;
      
      trackActivity(); // Track user activity for smart scrolling
      
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 24000
          }
        });
        
        await audioContext.resume();
        source = audioContext.createMediaStreamSource(mediaStream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        
        processor.onaudioprocess = (event) => {
          if (socket && socket.readyState === WebSocket.OPEN) {
            const input = event.inputBuffer.getChannelData(0);
            const pcm = float32ToInt16(input);
            socket.send(pcm.buffer);
          }
        };
        
        source.connect(processor);
        processor.connect(audioContext.destination);
        
        isRecording = true;
        document.getElementById("startVoiceBtn").disabled = true;
        document.getElementById("stopVoiceBtn").disabled = false;
        

        addLog("Voice recording started", "voice");
        
      } catch (e) {
        addLog(`Failed to start voice: ${e.message}`, "error");
      }
    }

    function stopVoice() {
      if (!isRecording) return;
      
      trackActivity(); // Track user activity for smart scrolling
      
      if (processor) {
        processor.disconnect();
        processor = null;
      }
      
      if (source) {
        source.disconnect();
        source = null;
      }
      
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
      
      isRecording = false;
      document.getElementById("startVoiceBtn").disabled = false;
      document.getElementById("stopVoiceBtn").disabled = true;
      

      addLog("Voice recording stopped", "voice");
      
      // Start thinking timer when user stops speaking
      startThinkingTimer();
    }

    function float32ToInt16(buffer) {
      const l = buffer.length;
      const buf = new Int16Array(l);
      for (let i = 0; i < l; i++) {
        buf[i] = Math.max(-1, Math.min(1, buffer[i])) * 0x7FFF;
      }
      return buf;
    }

    function base64ToArrayBuffer(base64) {
      const binaryString = atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    }

    async function playAudio(arrayBuffer) {
      try {
        if (!audioContext) {
          await initAudioContext();
        }
        
        // Convert Int16 PCM to Float32 for AudioWorklet (same as call-center project)
        const int16 = new Int16Array(arrayBuffer);
        const float32 = new Float32Array(int16.length);
        for (let i = 0; i < int16.length; i++) {
          float32[i] = int16[i] / (int16[i] < 0 ? 0x8000 : 0x7FFF);
        }
        
        // Send to AudioWorklet if available, otherwise fallback to direct playback
        if (workletNode) {
          workletNode.port.postMessage({ pcm: float32 });
        } else {
          // Fallback: create buffer source for direct playback
          const audioBuffer = audioContext.createBuffer(1, float32.length, audioContext.sampleRate);
          audioBuffer.getChannelData(0).set(float32);
          const source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          source.start();
        }
      } catch (e) {
        console.error("[Audio] Audio playback error:", e);
        addLog(`Audio playback error: ${e.message}`, "error");
      }
    }

    function showAudioIndicator() {
      // Audio indicator function - no longer needed but keeping for compatibility
      console.log('[Audio] Audio playback indicator');
    }



    function showThinkingIndicator() {
      const thinkingIndicator = document.getElementById('thinkingIndicator');
      thinkingIndicator.classList.add('active');
      addLog("AI is analyzing your request...", "voice");
    }

    function hideThinkingIndicator() {
      const thinkingIndicator = document.getElementById('thinkingIndicator');
      thinkingIndicator.classList.remove('active');
      if (thinkingTimeout) {
        clearTimeout(thinkingTimeout);
        thinkingTimeout = null;
      }
    }

    // Initialize marked library settings when page loads
    function initializeMarkdown() {
      if (typeof marked !== 'undefined') {
        marked.setOptions({
          breaks: true,
          sanitize: false,
          smartypants: true,
          gfm: true,
          renderer: new marked.Renderer()
        });
        
        // Custom renderer for better styling
        const renderer = new marked.Renderer();
        renderer.list = function(body, ordered) {
          const type = ordered ? 'ol' : 'ul';
          return `<${type} style="margin: 8px 0; padding-left: 20px;">${body}</${type}>`;
        };
        renderer.listitem = function(text) {
          return `<li style="margin: 3px 0; line-height: 1.4;">${text}</li>`;
        };
        
        marked.setOptions({ renderer });
      }
    }

    function startThinkingTimer() {
      // Show thinking indicator after 1 second of no activity (user stopped speaking)
      if (thinkingTimeout) {
        clearTimeout(thinkingTimeout);
      }
      
      thinkingTimeout = setTimeout(() => {
        if (!isProcessingResponse) {
          showThinkingIndicator();
        }
      }, 1000);
    }

    function updateStreamingTranscript(text, isPartial = true) {
      const streamingTranscript = document.getElementById('streamingTranscript');
      
      if (!text || text.trim() === '') {
        hideStreamingTranscript();
        return;
      }
      
      // Format the transcript text with markdown
      const formattedText = formatConversationText(text);
      
      // Update the transcript content
      streamingTranscript.innerHTML = formattedText;
      
      // Show the element and update its state
      streamingTranscript.classList.add('active');
      
      if (isPartial) {
        streamingTranscript.classList.add('partial');
      } else {
        streamingTranscript.classList.remove('partial');
        // Hide after final transcript is shown for a moment
        setTimeout(() => {
          hideStreamingTranscript();
        }, 2000);
      }
    }

    function hideStreamingTranscript() {
      const streamingTranscript = document.getElementById('streamingTranscript');
      streamingTranscript.classList.remove('active', 'partial');
    }

    // Initialize the application
    document.addEventListener('DOMContentLoaded', function() {
      initializeMarkdown();
      setMode('voice');
      // Initialize AI status on page load

    });
  </script>
</body>
</html>