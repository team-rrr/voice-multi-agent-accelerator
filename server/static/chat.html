<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>MedOrchestrator</title>
  <link rel="stylesheet" href="styles/main.css">
</head>
<body>
  <header>
    <div style="display: flex; align-items: center; justify-content: flex-start; gap: 24px; max-width: 900px; margin: 0 12px;">
      <!-- <div style="width:32px;height:32px;border-radius:50%;background:#fff;display:inline-block;"></div> -->
  <span style="font-size:2rem;font-weight:700;color:var(--background);letter-spacing:0.5px;">MedOrchestrator</span>
    </div>
  </header>
  <div class="layout">
    <nav class="sidebar">
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="chat.html" class="active">Chat</a></li>
        <li><a href="manage.html">Manage</a></li>
      </ul>
    </nav>
    <main>
      <div class="voice-assistant-ui" style="width:100%;margin:0;background:#fff;padding:32px 0 32px 0;border-radius:0;box-shadow:none;">
        <div class="subtitle">AI-powered appointment preparation with personalized guidance</div>
        <div class="mode-controls">
          <button class="mode-btn active" onclick="setMode('voice')" id="voiceModeBtn">Voice Mode</button>
          <button class="mode-btn" onclick="setMode('text')" id="textModeBtn">Text Mode</button>
        </div>
        <div class="controls">
          <button id="connectBtn" onclick="connectWebSocket()">Connect</button>
          <button id="disconnectBtn" onclick="disconnectWebSocket()" disabled>Disconnect</button>
          <button id="startVoiceBtn" onclick="startVoice()" disabled class="voice-only">Start Speaking</button>
          <button id="stopVoiceBtn" onclick="stopVoice()" disabled class="voice-only">Stop Speaking</button>
        </div>
  <div class="status disconnected" id="status">Disconnected - Click "Connect to AI Assistant" to start</div>
  <div id="audioIndicator" class="audio-indicator" style="display:none;">üîä Processing voice...</div>
        <div class="logs" id="logs">
          <div class="log-entry">
            <strong>Welcome!</strong> This is the MedOrchestrator.
            <br>‚Ä¢ Voice Mode: Speak about your medical appointments and get personalized preparation guidance
            <br>‚Ä¢ Text Mode: Type your appointment details for structured responses
            <br><br><strong>Try saying:</strong> "I have an appointment with Dr. Smith next week for chest pain"
          </div>
          <div class="log-entry" id="modeLog" style="font-size:0.98rem;color:var(--secondary);">
            2:21:41 PM:<br>Switched to VOICE mode
          </div>
        </div>
        <div class="send-row" id="textInputArea">
          <input type="text" id="messageInput" placeholder="Type your message here..." />
          <button id="sendBtn" onclick="sendTextMessage()">Send</button>
        </div>
        <!-- Card display container for appointment preparation guide -->
        <div id="cardDisplay" style="display:none;">
          <div class="card-title" id="cardTitle"></div>
          <div id="cardContent"></div>
        </div>
      </div>
    </main>
  </div>
  <footer>
    <p>&copy; 2025 MedOrchestrator</p>
  </footer>
  <!-- Move scripts to end of body to ensure all functions are defined before button onclicks -->
</body>
<script>
  let mediaStream;
  let audioContext;
  let source;
  let processor;
  let isRecording = false;
  let workletNode;
  let readyMessageShown = false;

  function setMode(mode) {
    currentMode = mode;

    // Update mode buttons
    document.getElementById('voiceModeBtn').classList.toggle('active', mode === 'voice');
    document.getElementById('textModeBtn').classList.toggle('active', mode === 'text');

    // Show/hide voice-specific buttons
    document.getElementById('startVoiceBtn').classList.toggle('active', mode === 'voice');
    document.getElementById('stopVoiceBtn').classList.toggle('active', mode === 'voice');

    // Show/hide text input area
    document.getElementById('textInputArea').classList.toggle('active', mode === 'text');

    addLog(`Switched to ${mode.toUpperCase()} mode`, 'info');
  }

  function addLog(message, type = 'info') {
    const logs = document.getElementById('logs');
    const entry = document.createElement('div');
    entry.className = `log-entry log-${type}`;

    // Extract the actual content after emoji/prefix for AI responses
    let displayMessage = message;
    let actualContent = message;

    // For AI responses, separate the emoji/prefix from the content
    if (message.includes('ü§ñ AI Response: ')) {
      const parts = message.split('ü§ñ AI Response: ');
      if (parts.length > 1) {
        displayMessage = 'ü§ñ AI Response: ';
        actualContent = parts[1];
      }
    }

    // Format only the actual content, not the emoji/prefix
    const formattedContent = actualContent === message ?
      formatConversationText(message) :
      displayMessage + formatConversationText(actualContent);

    entry.innerHTML = `<strong>${new Date().toLocaleTimeString()}</strong>: ${formattedContent}`;

    logs.appendChild(entry);
    logs.scrollTop = logs.scrollHeight;
  }

  function formatConversationText(text) {
    if (!text || typeof text !== 'string') return text;

    // Clean up the text first - remove excessive whitespace and normalize
    let cleaned = text
      .replace(/\r\n/g, '\n')  // Normalize line endings
      .replace(/\n\s*\n\s*\n/g, '\n\n')  // Remove triple+ newlines
      .trim();

    // Handle bold text formatting (**text** to <strong>text</strong>)
    cleaned = cleaned.replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>');

    // Split into sections for better processing
    let sections = cleaned.split(/\n\s*\n/);
    let formattedSections = [];

    for (let section of sections) {
      if (!section.trim()) continue; // Skip empty sections

      // Check if this section contains bullet points
      if (section.includes('\n‚Ä¢ ') || section.includes('\n* ') || section.includes('\n- ')) {
        let lines = section.split('\n');
        let beforeList = [];
        let listItems = [];
        let inList = false;

        for (let line of lines) {
          line = line.trim();
          if (!line) continue; // Skip empty lines

          if (line.startsWith('‚Ä¢ ') || line.startsWith('* ') || line.startsWith('- ')) {
            inList = true;
            // Remove the bullet and add as list item
            let itemText = line.replace(/^[‚Ä¢\*\-]\s*/, '');
            listItems.push(`<li>${itemText}</li>`);
          } else if (!inList) {
            beforeList.push(line);
          } else {
            // Text after bullets - could be continuation or new paragraph
            if (line.startsWith('‚Ä¢ ') || line.startsWith('* ') || line.startsWith('- ')) {
              let itemText = line.replace(/^[‚Ä¢\*\-]\s*/, '');
              listItems.push(`<li>${itemText}</li>`);
            } else {
              // This might be continuation of previous item or new paragraph
              // For now, treat as new paragraph after list
              if (listItems.length > 0) {
                formattedSections.push(
                  (beforeList.length > 0 ? `<p>${beforeList.join(' ')}</p>` : '') +
                  `<ul>${listItems.join('')}</ul>`
                );
                beforeList = [line];
                listItems = [];
                inList = false;
              }
            }
          }
        }

        // Add remaining content
        let result = '';
        if (beforeList.length > 0) {
          result += `<p>${beforeList.join(' ')}</p>`;
        }
        if (listItems.length > 0) {
          result += `<ul>${listItems.join('')}</ul>`;
        }

        if (result) formattedSections.push(result);

      } else {
        // Regular paragraph - no bullets
        formattedSections.push(`<p>${section.trim()}</p>`);
      }
    }

    return formattedSections.join('');
  }

  function updateStatus(text, connected) {
    const status = document.getElementById('status');
    status.textContent = text;
    status.className = `status ${connected ? 'connected' : 'disconnected'}`;
  }

  function connectWebSocket() {
    const wsProtocol = window.location.protocol === "https:" ? "wss" : "ws";
    const wsHost = window.location.host;
    const endpoint = currentMode === 'voice' ? '/ws/voice' : '/ws/text';

    socket = new WebSocket(`${wsProtocol}://${wsHost}${endpoint}`);
    socket.binaryType = "arraybuffer";

    socket.onopen = () => {
      addLog(`Connected to ${currentMode.toUpperCase()} endpoint`, "received");
      updateStatus(`Connected in ${currentMode.toUpperCase()} mode`, true);
      document.getElementById("connectBtn").disabled = true;
      document.getElementById("disconnectBtn").disabled = false;

      if (currentMode === 'voice') {
        document.getElementById("startVoiceBtn").disabled = false;
        initAudioContext();
      }
    };

    socket.onmessage = async (event) => {
      if (event.data instanceof ArrayBuffer) {
        // Handle binary audio data (prioritize this like call-center project)
        try {
          await playAudio(event.data);
          showAudioIndicator();
        } catch (e) {
          console.error("Failed to play audio:", e);
          addLog(`Audio playback error: ${e.message}`, "error");
        }
      } else if (typeof event.data === "string") {
        try {
          const data = JSON.parse(event.data);

          // Handle JSON messages for transcription, stop audio, etc.
          if (data.Kind === "StopAudio") {
            addLog("üõë Audio stopped", "voice");
            // Stop any ongoing audio playback
            if (workletNode) {
              workletNode.port.postMessage({ clear: true });
            }
          } else if (data.Kind === "Transcription") {
            addLog(`üìù ${data.Text}`, "received");
          } else if (data.Kind === "AudioData" && data.AudioData && data.AudioData.Data) {
            // Fallback: Decode base64 audio data (should not happen with raw_audio=True)
            const base64Audio = data.AudioData.Data;
            const audioBytes = base64ToArrayBuffer(base64Audio);
            await playAudio(audioBytes);
            showAudioIndicator();
          } else {
            // Handle regular text messages
            handleTextMessage(data);
          }
        } catch (e) {
          addLog(`Raw message: ${event.data}`, "received");
        }
      } else {
        console.log("Unknown message type:", event.data);
      }
    };

    socket.onclose = () => {
      addLog("Disconnected from AI Assistant", "info");
      updateStatus("Disconnected", false);
      document.getElementById("connectBtn").disabled = false;
      document.getElementById("disconnectBtn").disabled = true;
      document.getElementById("startVoiceBtn").disabled = true;
      document.getElementById("stopVoiceBtn").disabled = true;
      readyMessageShown = false; // Reset flag for next connection
    };

    socket.onerror = (err) => {
      addLog("WebSocket connection error", "error");
      console.error("WebSocket error:", err);
    };
  }

  function disconnectWebSocket() {
    if (isRecording) {
      stopVoice();
    }
    if (socket) {
      socket.close();
    }
  }

  function handleTextMessage(data) {
    const type = data.type || 'unknown';

    switch (type) {
      case 'ready':
        if (!readyMessageShown) {
          addLog(`‚úÖ ${data.text}`, "received");
          readyMessageShown = true;
        }
        break;
      case 'orchestration_response':
        // Handle multi-agent response
        if (data.spoken_response) {
          // Clean and format the AI response properly
          const cleanResponse = data.spoken_response.trim();
          if (cleanResponse) {
            addLog(`ü§ñ AI Response: ${cleanResponse}`, "voice");
          }
        }
        if (data.card_data) {
          displayCard(data.card_data);
          addLog(`üìã Generated appointment preparation checklist`, "received");
          // Log only agent name and function called by the orchestrator
          if (Array.isArray(data.card_data.agents)) {
            data.card_data.agents.forEach(agent => {
              const agentName = agent.name || agent.agent || 'UnknownAgent';
              const funcName = agent.function || agent.func || 'UnknownFunction';
              const logMsg = `[Orchestrator] Agent: ${agentName}, Function: ${funcName}`;
              console.log(logMsg);
              // addLog(logMsg, 'info');
            });
          }
        }
        break;
      case 'card':
        // Handle card data from voice orchestration
        if (data.payload) {
          displayCard(data.payload);
          // Only log once when card is first displayed
          if (!document.getElementById('cardDisplay').classList.contains('active')) {
            addLog(`üìã Generated appointment preparation checklist`, "received");
          }
        }
        break;
      case 'echo':
        addLog(`Echo: ${data.text.replace('Echo: ', '')}`, "received");
        break;
      case 'Transcription':
        addLog(`ü§ñ AI Response: ${data.text}`, "voice");
        break;
      case 'error':
        addLog(`‚ùå Error: ${data.text}`, "error");
        break;
      default:
        const text = data.text || JSON.stringify(data);
        addLog(`üì® ${type}: ${text}`, "received");
    }
  }

  function displayCard(cardData) {
    const cardDisplay = document.getElementById('cardDisplay');
    const cardTitle = document.getElementById('cardTitle');
    const cardContent = document.getElementById('cardContent');

    // Set title
    cardTitle.textContent = cardData.title || 'Appointment Preparation Guide';

    // Build card content
    let html = '';

    // Appointment details
    if (cardData.appointment_details) {
      html += '<div class="card-section">';
      html += '<h3>üìÖ Appointment Details</h3>';
      html += '<ul>';
      if (cardData.appointment_details.doctor) {
        html += `<li><strong>Doctor:</strong> ${cardData.appointment_details.doctor}</li>`;
      }
      if (cardData.appointment_details.reason) {
        html += `<li><strong>Reason:</strong> ${cardData.appointment_details.reason}</li>`;
      }
      if (cardData.appointment_details.timing) {
        html += `<li><strong>When:</strong> ${cardData.appointment_details.timing}</li>`;
      }
      html += '</ul>';
      html += '</div>';
    }

    // Preparation items
    if (cardData.preparation_items && cardData.preparation_items.length > 0) {
      html += '<div class="card-section">';
      html += '<h3>üìù What to Bring/Prepare</h3>';
      html += '<ul>';
      cardData.preparation_items.forEach(item => {
        html += `<li>${item}</li>`;
      });
      html += '</ul>';
      html += '</div>';
    }

    // Questions to ask
    if (cardData.questions_to_ask && cardData.questions_to_ask.length > 0) {
      html += '<div class="card-section">';
      html += '<h3>‚ùì Questions to Ask Your Doctor</h3>';
      html += '<ul>';
      cardData.questions_to_ask.forEach(question => {
        html += `<li>${question}</li>`;
      });
      html += '</ul>';
      html += '</div>';
    }

    // Follow-up actions
    if (cardData.follow_up_actions && cardData.follow_up_actions.length > 0) {
      html += '<div class="card-section">';
      html += '<h3>üìã After Your Appointment</h3>';
      html += '<ul>';
      cardData.follow_up_actions.forEach(action => {
        html += `<li>${action}</li>`;
      });
      html += '</ul>';
      html += '</div>';
    }

    cardContent.innerHTML = html;
    cardDisplay.classList.add('active');
  }

  function sendTextMessage() {
    const input = document.getElementById('messageInput');
    const message = input.value.trim();

    if (message && socket && socket.readyState === WebSocket.OPEN) {
      const payload = {
        type: "text",
        text: message
      };

      socket.send(JSON.stringify(payload));
      addLog(`üì§ Sent: ${message}`, "sent");
      input.value = '';
    }
  }

  async function initAudioContext() {
    try {
      audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });

      // Load AudioWorklet for better audio playback
      try {
        await audioContext.audioWorklet.addModule('/static/audio-processor.js');
        workletNode = new AudioWorkletNode(audioContext, 'ring-buffer-processor');
        workletNode.connect(audioContext.destination);
      } catch (e) {
        console.warn("AudioWorklet not available, using fallback:", e);
      }

      addLog("Audio context initialized", "voice");
    } catch (e) {
      addLog(`Failed to initialize audio: ${e.message}`, "error");
    }
  }

  async function startVoice() {
    if (isRecording) return;

    try {
      mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 24000
        }
      });

      await audioContext.resume();
      source = audioContext.createMediaStreamSource(mediaStream);
      processor = audioContext.createScriptProcessor(4096, 1, 1);

      processor.onaudioprocess = (event) => {
        if (socket && socket.readyState === WebSocket.OPEN) {
          const input = event.inputBuffer.getChannelData(0);
          const pcm = float32ToInt16(input);
          socket.send(pcm.buffer);
        }
      };

      source.connect(processor);
      processor.connect(audioContext.destination);

      isRecording = true;
      document.getElementById("startVoiceBtn").disabled = true;
      document.getElementById("stopVoiceBtn").disabled = false;

      addLog("üé§ Voice recording started", "voice");

    } catch (e) {
      addLog(`Failed to start voice: ${e.message}`, "error");
    }
  }

  function stopVoice() {
    if (!isRecording) return;

    if (processor) {
      processor.disconnect();
      processor = null;
    }

    if (source) {
      source.disconnect();
      source = null;
    }

    if (mediaStream) {
      mediaStream.getTracks().forEach(track => track.stop());
      mediaStream = null;
    }

    isRecording = false;
    document.getElementById("startVoiceBtn").disabled = false;
    document.getElementById("stopVoiceBtn").disabled = true;

    addLog("üõë Voice recording stopped", "voice");
  }

  function float32ToInt16(buffer) {
    const l = buffer.length;
    const buf = new Int16Array(l);
    for (let i = 0; i < l; i++) {
      buf[i] = Math.max(-1, Math.min(1, buffer[i])) * 0x7FFF;
    }
    return buf;
  }

  function base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  }

  async function playAudio(arrayBuffer) {
    try {
      if (!audioContext) {
        await initAudioContext();
      }

      // Convert Int16 PCM to Float32 for AudioWorklet (same as call-center project)
      const int16 = new Int16Array(arrayBuffer);
      const float32 = new Float32Array(int16.length);
      for (let i = 0; i < int16.length; i++) {
        float32[i] = int16[i] / (int16[i] < 0 ? 0x8000 : 0x7FFF);
      }

      // Send to AudioWorklet if available, otherwise fallback to direct playback
      if (workletNode) {
        workletNode.port.postMessage({ pcm: float32 });
      } else {
        // Fallback: create buffer source for direct playback
        const audioBuffer = audioContext.createBuffer(1, float32.length, audioContext.sampleRate);
        audioBuffer.getChannelData(0).set(float32);
        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);
        source.start();
      }
    } catch (e) {
      console.error("Error playing audio:", e);
      addLog(`Audio playback error: ${e.message}`, "error");
    }
  }

  function showAudioIndicator() {
    const indicator = document.getElementById('audioIndicator');
    indicator.classList.add('active');
    setTimeout(() => {
      indicator.classList.remove('active');
    }, 2000);
  }

  // Allow Enter key to send message in text mode
  document.getElementById('messageInput').addEventListener('keypress', (e) => {
    if (e.key === 'Enter') {
      sendTextMessage();
    }
  });

  // Initialize in voice mode
  setMode('voice');
</script>
